{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLDL2 Homework : Semi-Supervised Learning & Self-Supervised Learning"
      ],
      "metadata": {
        "id": "aapcoDMjfHJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iEQH-ClaRNoO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import random_split\n",
        "from torchsummary import summary\n",
        "from torchsummary import summary\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "bDbozwUVeeR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import AutoAugment, AutoAugmentPolicy # for augmenting data\n",
        "\n",
        "# Define training augmentations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "\n",
        "val_transform2 = transforms.Compose([\n",
        "  transforms.ToPILImage(),\n",
        "   transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 8\n"
      ],
      "metadata": {
        "id": "LiskzBZAisLF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"/content/gdrive/MyDrive/mldl2/MLDL2_HW\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DYys5SRchNg",
        "outputId": "7258bc8c-3d5b-40a7-f62d-b4c63c72206c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Do not modify the cell below!!!!**\n"
      ],
      "metadata": {
        "id": "Mc0Qb6gfiwO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root=\"./data/\",\n",
        "                                 train=True,\n",
        "                                 download=True,\n",
        "                                transform=train_transform\n",
        "                                 )\n",
        "\n",
        "val_dataset = datasets.CIFAR10(root=\"./data/\",\n",
        "                                train=False,\n",
        "                                download=True,\n",
        "                                 transform=train_transform\n",
        "                                )\n",
        "\n",
        "num_labeled = 5000\n",
        "num_unlabeled = len(train_dataset) - num_labeled\n",
        "\n",
        "indices = list(range(len(train_dataset)))\n",
        "labeled_indices = indices[:num_labeled]\n",
        "unlabeled_indices = indices[num_labeled:]\n",
        "\n",
        "for idx in unlabeled_indices:\n",
        "    train_dataset.targets[idx] = -1\n",
        "\n",
        "labeled_train_dataset = torch.utils.data.Subset(train_dataset, labeled_indices)\n",
        "unlabeled_train_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
        "\n",
        "labeled_train_loader = torch.utils.data.DataLoader(dataset=labeled_train_dataset,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True)\n",
        "\n",
        "unlabeled_train_loader = torch.utils.data.DataLoader(dataset=unlabeled_train_dataset,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apr6DnXiRPhL",
        "outputId": "101d678c-e2ab-42d3-dda3-6fc8305bfc69"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class val_Dataset2(Dataset):\n",
        "    def __init__(self,img_file, label_file, transform=None):\n",
        "        self.img =np.load(img_file)\n",
        "        self.labels = np.load(label_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.img[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image,label"
      ],
      "metadata": {
        "id": "BdRFIUxCYI78"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset2 = val_Dataset2(img_file=\"./valid_dataset2.npy\",label_file=\"./valid_dataset2_label.npy\",transform=val_transform2)\n",
        "val_loader2 = torch.utils.data.DataLoader(val_dataset2, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ubiNNxHjYMBz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"labeled_train_dataset size : \", len(labeled_train_dataset))\n",
        "print(\"unlabeled_train_dataset size : \", len(unlabeled_train_dataset))\n",
        "print(\"val_dataset size : \", len(val_dataset))\n",
        "print(\"val_dataset2 size : \", len(val_dataset2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCycWrVfb1B9",
        "outputId": "9de4fe33-2dbb-41fb-90b8-53071e6b776d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeled_train_dataset size :  5000\n",
            "unlabeled_train_dataset size :  45000\n",
            "val_dataset size :  10000\n",
            "val_dataset2 size :  9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = [0]*10\n",
        "for i in range(5000):\n",
        "  temp[labeled_train_dataset[i][-1]] = temp[labeled_train_dataset[i][-1]] + 1"
      ],
      "metadata": {
        "id": "MLGy_DVsaGc3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp"
      ],
      "metadata": {
        "id": "z_32IcOwavNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16906a0a-0219-4b4f-b3e7-92807dc3ae29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[505, 460, 519, 486, 519, 488, 519, 486, 520, 498]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmIqKhrqpkMK",
        "outputId": "dbad5073-e781-4242-a5c9-a7d52ead5d51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "mwiWInhUeLcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler. Below is very simple model with CNN. You can customize your own model and note that you are not limited to use any methods. **But you are not allowed to use pretrained weight**"
      ],
      "metadata": {
        "id": "pUvBbX-ieUdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_u = 75.0\n",
        "num_epochs=50"
      ],
      "metadata": {
        "id": "749Ymndr3Isb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Define ResNet18 as base model\n",
        "        resnet = resnet18(pretrained=False)\n",
        "        self.resnet_layers = nn.Sequential(*list(resnet.children())[:-2])  # Remove the last two layers\n",
        "\n",
        "        # Add your custom layers\n",
        "        self.fc1 = nn.Linear(512, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet_layers(x)\n",
        "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lCei_GspN_c4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "# 모델 인스턴스 생성\n",
        "# model = CustomMobileNet()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "pfKhtlrJidBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1e4e86-62c3-43e0-a18e-71bb956293d0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (resnet_layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=512, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "E78a7DYrhMAO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "from itertools import cycle\n",
        "train_losses = []\n",
        "val_losses1 = []\n",
        "val_losses2=[]\n",
        "\n",
        "train_acc = []\n",
        "val_acc1 = []\n",
        "val_acc2=[]\n",
        "ema_alpha = 0.99  # EMA decay factor\n",
        "consistency_criterion = F.mse_loss  # Mean Squared Error loss\n",
        "consistency_weight = 1\n",
        "# Create a cyclic iterator for the labeled dataset\n",
        "labeled_iter = cycle(labeled_train_loader)\n",
        "best_val_accuracy = 0.0  # Track the best validation accuracy\n",
        "early_stopping_counter = 0  # Initialize counter for early stopping\n",
        "patience = 5  # Patience for early stopping\n",
        "# Initialize the teacher model\n",
        "teacher_model = deepcopy(model).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss_labeled = 0.0\n",
        "    correct_predictions_labeled = 0\n",
        "    total_samples_labeled = 0\n",
        "\n",
        "    for unlabeled_data in tqdm(unlabeled_train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "        #Handle labeled data\n",
        "        labeled_data = next(labeled_iter)\n",
        "        inputs_l, labels_l = labeled_data\n",
        "        inputs_l, labels_l = inputs_l.to(device), labels_l.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Update teacher model (EMA)\n",
        "        for param, ema_param in zip(model.parameters(), teacher_model.parameters()):\n",
        "            ema_param.data.mul_(ema_alpha).add_((1.0 - ema_alpha) * param.data)\n",
        "\n",
        "        #레이블 데이타의 경우는 cross entropy loss\n",
        "        outputs_l = model(inputs_l)\n",
        "        loss_l = criterion(outputs_l, labels_l)\n",
        "        total_loss_labeled += loss_l.item()\n",
        "        _, predicted_labels_l = torch.max(outputs_l, 1)\n",
        "        correct_predictions_labeled += (predicted_labels_l == labels_l).sum().item()\n",
        "        total_samples_labeled += labels_l.size(0)\n",
        "\n",
        "        # Handle unlabeled data\n",
        "        inputs_u, _ = unlabeled_data\n",
        "        inputs_u = inputs_u.to(device)\n",
        "\n",
        "        outputs_u = model(inputs_u)\n",
        "        #수도 레이블 만들기\n",
        "        pseudo_labels = torch.argmax(outputs_u, dim=1)\n",
        "\n",
        "        # Consistency regularization\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs_u = teacher_model(inputs_u)\n",
        "            #mse loss사용\n",
        "            consistency_loss = consistency_criterion(outputs_u, teacher_outputs_u)\n",
        "\n",
        "        # Sample the same number of unlabeled samples as labeled samples\n",
        "        indices = torch.randperm(inputs_u.size(0))[:inputs_l.size(0)]\n",
        "        inputs_u = inputs_u[indices]\n",
        "        pseudo_labels = pseudo_labels[indices]\n",
        "\n",
        "        # Combine labeled and pseudo-labeled data for loss calculation\n",
        "        combined_inputs = torch.cat((inputs_l, inputs_u), dim=0)\n",
        "        combined_labels = torch.cat((labels_l, pseudo_labels), dim=0)\n",
        "        #combined loss backprop\n",
        "        optimizer.zero_grad()\n",
        "        outputs_combined = model(combined_inputs)\n",
        "        # print(criterion(outputs_combined, combined_labels) ,consistency_loss)\n",
        "        loss_combined = criterion(outputs_combined, combined_labels) + consistency_weight * consistency_loss\n",
        "        loss_combined.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Update the EMA parameters of the teacher model at the end of each epoch\n",
        "    for param, ema_param in zip(model.parameters(), teacher_model.parameters()):\n",
        "        ema_param.data.copy_(param.data)\n",
        "\n",
        "    average_loss_labeled = total_loss_labeled / len(labeled_train_loader.dataset)\n",
        "    train_losses.append(average_loss_labeled)\n",
        "\n",
        "    accuracy_labeled = correct_predictions_labeled / total_samples_labeled * 100\n",
        "    train_acc.append(accuracy_labeled)\n",
        "    print(f'Training - Epoch {epoch + 1}/{num_epochs}, Labeled Data - Average Loss: {average_loss_labeled}, Accuracy: {accuracy_labeled:.2f}%')\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_samples = 0\n",
        "     # Validation loop for val_dataset1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data in val_loader:\n",
        "            inputs_val, labels_val = val_data\n",
        "            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
        "\n",
        "            outputs_val = model(inputs_val)\n",
        "            #validation은 evaluate용이기 때문에 mse가 아닌 crossentropy loss적용\n",
        "            loss_val = criterion(outputs_val, labels_val)\n",
        "            val_loss += loss_val.item()\n",
        "\n",
        "            _, predicted_labels_val = torch.max(outputs_val, 1)\n",
        "            val_correct_predictions += (predicted_labels_val == labels_val).sum().item()\n",
        "            val_total_samples += labels_val.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_losses1.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_samples * 100\n",
        "    val_acc1.append(val_accuracy)\n",
        "    #Validation loop for val_dataset2\n",
        "    val_loss2 = 0.0\n",
        "    val_correct_predictions2 = 0\n",
        "    val_total_samples2 = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data2 in val_loader2:\n",
        "            inputs_val2, labels_val2 = val_data2\n",
        "            inputs_val2, labels_val2 = inputs_val2.to(device), labels_val2.to(device)\n",
        "\n",
        "            outputs_val2 = model(inputs_val2)\n",
        "            loss_val2 = criterion(outputs_val2, labels_val2)\n",
        "            val_loss2 += loss_val2.item()\n",
        "\n",
        "            _, predicted_labels_val2 = torch.max(outputs_val2, 1)\n",
        "            val_correct_predictions2 += (predicted_labels_val2 == labels_val2).sum().item()\n",
        "            val_total_samples2 += labels_val2.size(0)\n",
        "\n",
        "\n",
        "    average_val_loss2 = val_loss2 / len(val_loader2.dataset)\n",
        "    val_losses2.append(average_val_loss2)\n",
        "    val_accuracy2 = val_correct_predictions2 / val_total_samples2 * 100\n",
        "    val_acc2.append(val_accuracy2)\n",
        "    val_accuracy=(val_accuracy2+val_accuracy)/2\n",
        "    print(f'Validation - Epoch {epoch + 1}/{num_epochs},  Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        early_stopping_counter = 0\n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/mldl2/MLDL2_HW/semi_best_model.pth')\n",
        "    else:\n",
        "      # 최고 검증 정확도가 갱신되지 않으면 조기 종료 카운터를 증가시킵니다.\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"No improvement in validation accuracy for {patience} epochs. Early stopping...\")\n",
        "            break  # Stop training\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqm9neByLFWC",
        "outputId": "1e464f1f-03a7-4cc6-e954-5f4e33e21fc6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 5625/5625 [02:42<00:00, 34.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 1/50, Labeled Data - Average Loss: 2.4790462924957275, Accuracy: 17.66%\n",
            "Validation - Epoch 1/50,  Accuracy: 32.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 5625/5625 [02:27<00:00, 38.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 2/50, Labeled Data - Average Loss: 1.4179064218916, Accuracy: 57.63%\n",
            "Validation - Epoch 2/50,  Accuracy: 44.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 5625/5625 [02:25<00:00, 38.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 3/50, Labeled Data - Average Loss: 0.7965172659895383, Accuracy: 77.87%\n",
            "Validation - Epoch 3/50,  Accuracy: 43.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 5625/5625 [02:27<00:00, 38.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 4/50, Labeled Data - Average Loss: 0.5013538106373511, Accuracy: 86.66%\n",
            "Validation - Epoch 4/50,  Accuracy: 46.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 5625/5625 [02:29<00:00, 37.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 5/50, Labeled Data - Average Loss: 0.3449353693897836, Accuracy: 91.10%\n",
            "Validation - Epoch 5/50,  Accuracy: 46.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 5625/5625 [02:33<00:00, 36.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 6/50, Labeled Data - Average Loss: 0.28471065667972434, Accuracy: 92.87%\n",
            "Validation - Epoch 6/50,  Accuracy: 47.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 5625/5625 [02:29<00:00, 37.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 7/50, Labeled Data - Average Loss: 0.25253495187364167, Accuracy: 93.86%\n",
            "Validation - Epoch 7/50,  Accuracy: 47.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 5625/5625 [02:29<00:00, 37.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 8/50, Labeled Data - Average Loss: 0.21060919337813103, Accuracy: 95.03%\n",
            "Validation - Epoch 8/50,  Accuracy: 48.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 5625/5625 [02:26<00:00, 38.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 9/50, Labeled Data - Average Loss: 0.18952732255064839, Accuracy: 95.58%\n",
            "Validation - Epoch 9/50,  Accuracy: 47.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 5625/5625 [02:24<00:00, 38.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 10/50, Labeled Data - Average Loss: 0.16957034800788534, Accuracy: 96.07%\n",
            "Validation - Epoch 10/50,  Accuracy: 47.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 5625/5625 [02:26<00:00, 38.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 11/50, Labeled Data - Average Loss: 0.1700125508384648, Accuracy: 96.15%\n",
            "Validation - Epoch 11/50,  Accuracy: 47.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 5625/5625 [02:26<00:00, 38.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 12/50, Labeled Data - Average Loss: 0.15416966727042783, Accuracy: 96.51%\n",
            "Validation - Epoch 12/50,  Accuracy: 45.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 5625/5625 [02:26<00:00, 38.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Epoch 13/50, Labeled Data - Average Loss: 0.14866263759557186, Accuracy: 96.62%\n",
            "Validation - Epoch 13/50,  Accuracy: 47.30%\n",
            "No improvement in validation accuracy for 5 epochs. Early stopping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(val_acc1, label='Validation accuracy1')\n",
        "plt.plot(val_acc2, label='Validation accuracy2')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "TCjlfpPzlgp2",
        "outputId": "d177af9a-c83a-493f-87c4-beb7c4063113"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses1, label='Validation loss1')\n",
        "plt.plot(val_losses2, label='Validation loss2')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "NlOC-EP693i7",
        "outputId": "98757a04-6926-4c4c-b135-f15d79fdc23b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_path=\"/content/gdrive/MyDrive/mldl2/MLDL2_HW/semi_best_model.pth\"\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(pt_path))\n",
        "model.to(device)\n",
        "val_correct_predictions2=0\n",
        "val_loss2=0\n",
        "with torch.no_grad():\n",
        "    for val_data2 in val_loader:\n",
        "            inputs_val2, labels_val2 = val_data2\n",
        "            inputs_val2, labels_val2 = inputs_val2.to(device), labels_val2.to(device)\n",
        "            outputs_val2 = model(inputs_val2)\n",
        "            loss_val2 = criterion(outputs_val2, labels_val2)\n",
        "            val_loss2 += loss_val2.item()\n",
        "            _, predicted_labels_val2 = torch.max(outputs_val2, 1)\n",
        "            val_correct_predictions2 += (predicted_labels_val2 == labels_val2).sum().item()\n",
        "val_accuracy2 = val_correct_predictions2 / val_total_samples2 * 100\n",
        "print(val_accuracy2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03pPM6f_htGM",
        "outputId": "7a0f74af-d3b9-4b1b-bc58-a2e9b4e99c40"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.252631578947366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_file, transform=None):\n",
        "        self.img =np.load(img_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.img[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "test_dataset = TestDataset(img_file=\"./test_data.npy\",transform=val_transform2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "def test(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  ### List to store predictions\n",
        "  test_predictions = []\n",
        "\n",
        "  with torch.inference_mode():\n",
        "      for i, data in enumerate(tqdm(test_loader)):\n",
        "\n",
        "          data = data.float().to(device)\n",
        "          output = model(data)\n",
        "          ### Get most likely predicted  with argmax\n",
        "          predicted_labels = torch.argmax(output, dim=1)\n",
        "\n",
        "          test_predictions.extend(predicted_labels.cpu().tolist())\n",
        "\n",
        "  return test_predictions\n",
        "predictions = test(model, test_loader)\n",
        "### Create CSV file with predictions\n",
        "saved_path=\"2019-17577_정지후_semi_HW3.csv\"\n",
        "with open(saved_path, \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOD4aNepa-e4",
        "outputId": "2aa815b6-5ee1-4baf-8162-bf8ce7da761c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [00:00<00:00, 194.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-Supervised Learning**\n",
        "https://github.com/p3i0t/SimCLR-CIFAR10/tree/master 이 모델 참고했다."
      ],
      "metadata": {
        "id": "WeCiS8jETK4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet18, resnet34\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_encoder, projection_dim=128):\n",
        "        super().__init__()\n",
        "        #base encoder모델 pretrained없이 불러오기\n",
        "        self.enc = base_encoder(pretrained=False)\n",
        "        self.feature_dim = self.enc.fc.in_features\n",
        "        # Customize SimCLR for CIFAR10.\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.enc.maxpool = nn.Identity()\n",
        "        self.enc.fc = nn.Identity()\n",
        "        # Add MLP projection.\n",
        "        self.projection_dim = projection_dim\n",
        "        self.projector = nn.Sequential(nn.Linear(self.feature_dim, 2048),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(2048, projection_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.enc(x)\n",
        "        projection = self.projector(feature)\n",
        "        return feature, projection\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "      # 현재 값 및 누적값 갱신 메서드\n",
        "        # val: 현재 값\n",
        "        # n: 값의 개수 (기본값은 1)\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count # 새로운 평균 계산\n",
        "\n",
        "\n",
        "#noise-contrastive loss\n",
        "def nt_xent(x, t=0.5):\n",
        "   # 입력 텐서 정규화\n",
        "    x = F.normalize(x, dim=1)\n",
        "    x_scores =  (x @ x.t()).clamp(min=1e-7)\n",
        "    # temparature 적용하여 스케일 조정\n",
        "    x_scale = x_scores / t\n",
        "    # 대각선 항을 큰 음수 값으로 대체\n",
        "    x_scale = x_scale - torch.eye(x_scale.size(0)).to(x_scale.device) * 1e5\n",
        "    # 대조 대상 생성\n",
        "    targets = torch.arange(x.size()[0])\n",
        "\n",
        "    targets[::2] += 1\n",
        "    targets[1::2] -= 1\n",
        "    return F.cross_entropy(x_scale, targets.long().to(x_scale.device))\n",
        "\n",
        "\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "def get_color_distortion(s=0.5):  # 0.5 for CIFAR10 by default\n",
        "    # s is the strength of color distortion\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort\n",
        "\n",
        "data_dir = \"./data\"\n",
        "\n",
        "# model\n",
        "backbone = \"resnet18\"\n",
        "projection_dim = 128\n",
        "seed = 42\n",
        "batch_size = 512\n",
        "workers = 16\n",
        "epochs = 10\n",
        "log_interval = 50\n",
        "\n",
        "# loss options\n",
        "optimizer = 'sgd'\n",
        "learning_rate = 0.2\n",
        "momentum = 0.9\n",
        "weight_decay = 1.0e-6\n",
        "temperature = 0.5\n",
        "\n",
        "# finetune options\n",
        "finetune_epochs = 100\n",
        "load_epoch = 1000\n",
        "\n",
        "\n",
        "def train(train_loader) -> None:\n",
        "\n",
        "    assert backbone in ['resnet18', 'resnet34']\n",
        "    base_encoder = eval(backbone)\n",
        "    model = SimCLR(base_encoder, projection_dim=projection_dim).cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay,\n",
        "        nesterov=True)\n",
        "\n",
        "    scheduler = LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "            step,\n",
        "            epochs * len(train_loader),\n",
        "            learning_rate,  # lr_lambda computes multiplicative factor\n",
        "            1e-3))\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss_meter = AverageMeter(\"SimCLR_loss\")\n",
        "        train_bar = tqdm(train_loader)\n",
        "        for x, y in train_bar:\n",
        "            #train 시작 for unlabeled data\n",
        "            sizes = x.size()\n",
        "            x = x.view(sizes[0] * 2, sizes[2], sizes[3], sizes[4]).cuda(non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            feature, rep = model(x)\n",
        "            #loss 계산\n",
        "            loss = nt_xent(rep, temperature)\n",
        "            loss.backward()\n",
        "            #gradient clipping for prevent exploding gradinet\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), x.size(0))\n",
        "            train_bar.set_description(\"Train epoch {}, SimCLR loss: {:.4f}\".format(epoch, loss_meter.avg))\n",
        "\n",
        "        # save checkpoint very log_interval epochs\n",
        "        if epoch >= 10 and epoch % 10 == 0:\n",
        "            checkpoint_path = '/content/gdrive/MyDrive/mldl2/MLDL2_HW/simclr_{}_epoch{}.pt'.format(backbone, epoch)\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(\"==> Saved checkpoint. Train epoch {}, Model saved at: {}\".format(epoch, checkpoint_path))\n"
      ],
      "metadata": {
        "id": "Cbbil4SIDvIU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform1 = transforms.Compose([transforms.RandomResizedCrop(32),\n",
        "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                          get_color_distortion(s=0.5),\n",
        "                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                                          ])\n",
        "\n",
        "transform2 = transforms.Compose([transforms.RandomResizedCrop(32),\n",
        "                                 get_color_distortion(s=0.5),\n",
        "                                  transforms.RandomHorizontalFlip(p=0.3),\n",
        "                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                                      ])\n",
        "\n",
        "class DoubleTransform(Dataset):\n",
        "    def __init__(self, dataset, transform1, transform2):\n",
        "        self.dataset = dataset\n",
        "        self.transform1 = transform1\n",
        "        self.transform2 = transform2\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.dataset[idx][0], self.dataset[idx][1]\n",
        "        img1 = self.transform1(img)\n",
        "        img2 = self.transform2(img)\n",
        "        imgs = [img1, img2]\n",
        "        return torch.stack(imgs), target\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "#unlabeled_train_dataset 사용\n",
        "double_transform = DoubleTransform(unlabeled_train_dataset, transform1, transform2)\n",
        "\n",
        "# DataLoader 설정\n",
        "train_loader = DataLoader(\n",
        "    double_transform,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "r8VhdaN9cJ44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59449e92-2790-4c09-84b3-e8b31ae7ada3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8V9-LZhE5DO",
        "outputId": "2a3c6418-aa83-48ce-b268-5e4c7b34681d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 1, SimCLR loss: 6.2714: 100%|██████████| 87/87 [00:38<00:00,  2.24it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 2, SimCLR loss: 6.0786: 100%|██████████| 87/87 [00:38<00:00,  2.24it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 3, SimCLR loss: 6.0283: 100%|██████████| 87/87 [00:38<00:00,  2.24it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 4, SimCLR loss: 5.9972: 100%|██████████| 87/87 [00:40<00:00,  2.17it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 5, SimCLR loss: 5.9750: 100%|██████████| 87/87 [00:39<00:00,  2.23it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 6, SimCLR loss: 5.9656: 100%|██████████| 87/87 [00:38<00:00,  2.25it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 7, SimCLR loss: 5.9514: 100%|██████████| 87/87 [00:39<00:00,  2.21it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 8, SimCLR loss: 5.9383: 100%|██████████| 87/87 [00:39<00:00,  2.23it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 9, SimCLR loss: 5.9363: 100%|██████████| 87/87 [00:40<00:00,  2.14it/s]\n",
            "  0%|          | 0/87 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "Train epoch 10, SimCLR loss: 5.9313: 100%|██████████| 87/87 [00:39<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Saved checkpoint. Train epoch 10, Model saved at: /content/gdrive/MyDrive/mldl2/MLDL2_HW/simclr_resnet18_epoch10.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torchvision.models import resnet18, resnet34\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class LinModel(nn.Module):\n",
        "    \"\"\"Linear wrapper of encoder.\"\"\"\n",
        "    def __init__(self, encoder: nn.Module, feature_dim: int, n_classes: int):\n",
        "        super().__init__()\n",
        "        self.enc = encoder\n",
        "        self.feature_dim = feature_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.lin = nn.Linear(self.feature_dim, self.n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(self.enc(x))\n",
        "\n",
        "\n",
        "def run_epoch(model, dataloader, epoch, optimizer=None, scheduler=None):\n",
        "  # 옵티마이저가 주어지면 학습 모드로, 그렇지 않으면 평가 모드로 설정합니다.\n",
        "\n",
        "    if optimizer:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    #loss, accuracy function 설정\n",
        "    loss_meter = AverageMeter('loss')\n",
        "    acc_meter = AverageMeter('acc')\n",
        "    loader_bar = tqdm(dataloader)\n",
        "    for x, y in loader_bar:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        logits = model(x)\n",
        "        # CrossEntropy 손실 계산\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "      # 학습 중일 때는 loss backward\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "        #정확도 계산\n",
        "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
        "        # AverageMeter를 사용하여 손실 및 정확도 업데이트\n",
        "        loss_meter.update(loss.item(), x.size(0))\n",
        "        acc_meter.update(acc.item(), x.size(0))\n",
        "        if optimizer:\n",
        "            loader_bar.set_description(\"Train epoch {}, loss: {:.4f}, acc: {:.4f}\"\n",
        "                                       .format(epoch, loss_meter.avg, acc_meter.avg))\n",
        "        else:\n",
        "            loader_bar.set_description(\"Test epoch {}, loss: {:.4f}, acc: {:.4f}\"\n",
        "                                       .format(epoch, loss_meter.avg, acc_meter.avg))\n",
        "    return loss_meter.avg, acc_meter.avg\n",
        "\n",
        "\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "    print(\"total_steps\",total_steps)\n",
        "    \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "train_losses = []\n",
        "val_losses1 = []\n",
        "val_losses2=[]\n",
        "\n",
        "train_accs = []\n",
        "val_acc1 = []\n",
        "val_acc2=[]\n",
        "best_val_accuracy = 0.0  # Track the best validation accuracy\n",
        "early_stopping_counter = 0  # Initialize counter for early stopping\n",
        "patience = 5  # Patience for early stopping\n",
        "\n",
        "pt_path=\"/content/gdrive/MyDrive/mldl2/MLDL2_HW/simclr_resnet18_epoch10.pt\"\n",
        "def finetune() -> None:\n",
        "    #finetuning with labeled_train_dataset\n",
        "    train_set = labeled_train_dataset\n",
        "    n_classes = 10\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "    # Prepare model\n",
        "    base_encoder = eval(backbone)\n",
        "    pre_model = SimCLR(base_encoder, projection_dim=projection_dim).cuda()\n",
        "\n",
        "    pre_model.load_state_dict(torch.load(pt_path))\n",
        "    #linear model도 준비\n",
        "    model = LinModel(pre_model.enc, feature_dim=pre_model.feature_dim, n_classes=10)\n",
        "    model = model.cuda()\n",
        "\n",
        "    model.enc.requires_grad = False\n",
        "    parameters = [param for param in model.parameters() if param.requires_grad is True]  # trainable parameters.\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        parameters,\n",
        "        0.2,\n",
        "        momentum=momentum,\n",
        "        weight_decay=0.,\n",
        "        nesterov=True)\n",
        "\n",
        "    scheduler = LambdaLR(\n",
        "        optimizer,\n",
        "\n",
        "        lr_lambda=lambda step: get_lr(  # pylint: disable=g-long-lambda\n",
        "            step,\n",
        "            epochs * len(train_loader),\n",
        "            learning_rate,  # lr_lambda computes multiplicative factor\n",
        "            1e-3))\n",
        "\n",
        "    optimal_loss, optimal_acc = 1e5, 0.\n",
        "    best_val_accuracy=0\n",
        "    #train,validation loss 계산\n",
        "    for epoch in range(1, finetune_epochs + 1):\n",
        "        train_loss, train_acc = run_epoch(model, train_loader, epoch, optimizer, scheduler)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        test_loss, test_acc = run_epoch(model, val_loader, epoch)\n",
        "        test_loss2, test_acc2 = run_epoch(model, val_loader2, epoch)\n",
        "        val_losses1.append(test_loss)\n",
        "        val_losses2.append(test_loss2)\n",
        "        val_acc1.append(test_acc)\n",
        "        val_acc2.append(test_acc2)\n",
        "\n",
        "        val_accuracy= (test_acc+test_acc2)/2\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            early_stopping_counter = 0\n",
        "            torch.save(model.state_dict(), '/content/gdrive/MyDrive/mldl2/MLDL2_HW/self_best_model.pth')\n",
        "        else:\n",
        "          # 최고 검증 정확도가 갱신되지 않으면 조기 종료 카운터를 증가시킵니다.\n",
        "            early_stopping_counter += 1\n",
        "            if early_stopping_counter >= patience:\n",
        "                print(f\"No improvement in validation accuracy for {patience} epochs. Early stopping...\")\n",
        "                break  # Stop training\n",
        "    # logger.info(\"Best Test Acc: {:.4f}\".format(optimal_acc))"
      ],
      "metadata": {
        "id": "ZtCpu7YoD68L"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "615pRzM3SnS7",
        "outputId": "6a55eb19-6f3b-4e85-c8f3-7e63ebe8c189"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.6310, acc: 0.1230:  22%|██▏       | 2/9 [00:00<00:01,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.5354, acc: 0.1595:  33%|███▎      | 3/9 [00:00<00:01,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.4941, acc: 0.1831:  44%|████▍     | 4/9 [00:01<00:01,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.4815, acc: 0.1918:  56%|█████▌    | 5/9 [00:01<00:01,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.4874, acc: 0.2100:  67%|██████▋   | 6/9 [00:01<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.4447, acc: 0.2243:  78%|███████▊  | 7/9 [00:01<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.3745, acc: 0.2363:  89%|████████▉ | 8/9 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 1, loss: 2.3384, acc: 0.2530: 100%|██████████| 9/9 [00:02<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 1, loss: 1.8496, acc: 0.3364: 100%|██████████| 1250/1250 [00:10<00:00, 123.03it/s]\n",
            "Test epoch 1, loss: 2.0268, acc: 0.2977: 100%|██████████| 1188/1188 [00:09<00:00, 129.68it/s]\n",
            "Train epoch 2, loss: 1.6949, acc: 0.3965:  11%|█         | 1/9 [00:00<00:02,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.7149, acc: 0.3848:  22%|██▏       | 2/9 [00:00<00:01,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.6569, acc: 0.3984:  33%|███▎      | 3/9 [00:00<00:01,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.6377, acc: 0.4023:  44%|████▍     | 4/9 [00:01<00:01,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.6095, acc: 0.4148:  56%|█████▌    | 5/9 [00:01<00:01,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.5911, acc: 0.4186:  67%|██████▋   | 6/9 [00:01<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.6033, acc: 0.4238:  78%|███████▊  | 7/9 [00:01<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.5963, acc: 0.4255:  89%|████████▉ | 8/9 [00:02<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 2, loss: 1.5863, acc: 0.4314: 100%|██████████| 9/9 [00:02<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 2, loss: 1.7776, acc: 0.3962: 100%|██████████| 1250/1250 [00:10<00:00, 117.87it/s]\n",
            "Test epoch 2, loss: 1.9757, acc: 0.3628: 100%|██████████| 1188/1188 [00:08<00:00, 137.59it/s]\n",
            "Train epoch 3, loss: 1.5346, acc: 0.4727:  11%|█         | 1/9 [00:00<00:02,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.4225, acc: 0.4873:  22%|██▏       | 2/9 [00:00<00:01,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.3541, acc: 0.5052:  33%|███▎      | 3/9 [00:00<00:01,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.3228, acc: 0.5259:  44%|████▍     | 4/9 [00:01<00:01,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.2900, acc: 0.5387:  56%|█████▌    | 5/9 [00:01<00:01,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.2739, acc: 0.5492:  67%|██████▋   | 6/9 [00:01<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.2659, acc: 0.5497:  78%|███████▊  | 7/9 [00:01<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.2440, acc: 0.5557:  89%|████████▉ | 8/9 [00:02<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 3, loss: 1.2279, acc: 0.5608: 100%|██████████| 9/9 [00:02<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 3, loss: 1.3915, acc: 0.4884: 100%|██████████| 1250/1250 [00:10<00:00, 122.53it/s]\n",
            "Test epoch 3, loss: 1.5999, acc: 0.4344: 100%|██████████| 1188/1188 [00:08<00:00, 133.59it/s]\n",
            "Train epoch 4, loss: 1.0739, acc: 0.6074:  11%|█         | 1/9 [00:00<00:02,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 1.0546, acc: 0.6104:  22%|██▏       | 2/9 [00:00<00:01,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 1.0210, acc: 0.6270:  33%|███▎      | 3/9 [00:00<00:01,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 1.0139, acc: 0.6377:  44%|████▍     | 4/9 [00:01<00:01,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 0.9966, acc: 0.6449:  56%|█████▌    | 5/9 [00:01<00:01,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 0.9889, acc: 0.6504:  67%|██████▋   | 6/9 [00:01<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 0.9845, acc: 0.6549:  78%|███████▊  | 7/9 [00:01<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 0.9667, acc: 0.6616:  89%|████████▉ | 8/9 [00:02<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 4, loss: 0.9556, acc: 0.6656: 100%|██████████| 9/9 [00:02<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 4, loss: 1.4263, acc: 0.4941: 100%|██████████| 1250/1250 [00:10<00:00, 119.84it/s]\n",
            "Test epoch 4, loss: 1.6619, acc: 0.4339: 100%|██████████| 1188/1188 [00:09<00:00, 127.55it/s]\n",
            "Train epoch 5, loss: 0.8420, acc: 0.7012:  11%|█         | 1/9 [00:00<00:02,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.8325, acc: 0.7061:  22%|██▏       | 2/9 [00:00<00:02,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.8030, acc: 0.7266:  33%|███▎      | 3/9 [00:00<00:01,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7988, acc: 0.7363:  44%|████▍     | 4/9 [00:01<00:01,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7836, acc: 0.7438:  56%|█████▌    | 5/9 [00:01<00:01,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7736, acc: 0.7477:  67%|██████▋   | 6/9 [00:01<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7673, acc: 0.7539:  78%|███████▊  | 7/9 [00:01<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7500, acc: 0.7615:  89%|████████▉ | 8/9 [00:02<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 5, loss: 0.7387, acc: 0.7676: 100%|██████████| 9/9 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 5, loss: 1.3701, acc: 0.5169: 100%|██████████| 1250/1250 [00:10<00:00, 122.25it/s]\n",
            "Test epoch 5, loss: 1.6344, acc: 0.4512: 100%|██████████| 1188/1188 [00:08<00:00, 139.90it/s]\n",
            "Train epoch 6, loss: 0.6166, acc: 0.8242:  11%|█         | 1/9 [00:00<00:02,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.6181, acc: 0.8223:  22%|██▏       | 2/9 [00:00<00:01,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5958, acc: 0.8294:  33%|███▎      | 3/9 [00:00<00:01,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5927, acc: 0.8345:  44%|████▍     | 4/9 [00:01<00:01,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5800, acc: 0.8375:  56%|█████▌    | 5/9 [00:01<00:01,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5718, acc: 0.8418:  67%|██████▋   | 6/9 [00:01<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5678, acc: 0.8440:  78%|███████▊  | 7/9 [00:01<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5546, acc: 0.8486:  89%|████████▉ | 8/9 [00:02<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 6, loss: 0.5443, acc: 0.8535: 100%|██████████| 9/9 [00:02<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 6, loss: 1.3551, acc: 0.5355: 100%|██████████| 1250/1250 [00:10<00:00, 123.37it/s]\n",
            "Test epoch 6, loss: 1.6491, acc: 0.4585: 100%|██████████| 1188/1188 [00:08<00:00, 132.77it/s]\n",
            "Train epoch 7, loss: 0.4301, acc: 0.8926:  11%|█         | 1/9 [00:00<00:02,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4449, acc: 0.8838:  22%|██▏       | 2/9 [00:00<00:01,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4360, acc: 0.8926:  33%|███▎      | 3/9 [00:00<00:01,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4336, acc: 0.8965:  44%|████▍     | 4/9 [00:01<00:01,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4250, acc: 0.9027:  56%|█████▌    | 5/9 [00:01<00:01,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4209, acc: 0.9043:  67%|██████▋   | 6/9 [00:01<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4190, acc: 0.9060:  78%|███████▊  | 7/9 [00:01<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4119, acc: 0.9077:  89%|████████▉ | 8/9 [00:02<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 7, loss: 0.4054, acc: 0.9123: 100%|██████████| 9/9 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 7, loss: 1.3822, acc: 0.5397: 100%|██████████| 1250/1250 [00:10<00:00, 116.26it/s]\n",
            "Test epoch 7, loss: 1.6844, acc: 0.4661: 100%|██████████| 1188/1188 [00:09<00:00, 128.80it/s]\n",
            "Train epoch 8, loss: 0.3370, acc: 0.9414:  11%|█         | 1/9 [00:00<00:02,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3400, acc: 0.9365:  22%|██▏       | 2/9 [00:00<00:01,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3347, acc: 0.9388:  33%|███▎      | 3/9 [00:00<00:01,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3379, acc: 0.9365:  44%|████▍     | 4/9 [00:01<00:01,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3331, acc: 0.9395:  56%|█████▌    | 5/9 [00:01<00:01,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3340, acc: 0.9395:  67%|██████▋   | 6/9 [00:01<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3336, acc: 0.9397:  78%|███████▊  | 7/9 [00:01<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3278, acc: 0.9421:  89%|████████▉ | 8/9 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 8, loss: 0.3233, acc: 0.9442: 100%|██████████| 9/9 [00:02<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 8, loss: 1.2828, acc: 0.5625: 100%|██████████| 1250/1250 [00:10<00:00, 119.00it/s]\n",
            "Test epoch 8, loss: 1.5832, acc: 0.4889: 100%|██████████| 1188/1188 [00:08<00:00, 136.95it/s]\n",
            "Train epoch 9, loss: 0.2677, acc: 0.9609:  11%|█         | 1/9 [00:00<00:02,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2723, acc: 0.9600:  22%|██▏       | 2/9 [00:00<00:02,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2720, acc: 0.9616:  33%|███▎      | 3/9 [00:00<00:01,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2796, acc: 0.9585:  44%|████▍     | 4/9 [00:01<00:01,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2768, acc: 0.9598:  56%|█████▌    | 5/9 [00:01<00:01,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2742, acc: 0.9616:  67%|██████▋   | 6/9 [00:01<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2735, acc: 0.9623:  78%|███████▊  | 7/9 [00:01<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2692, acc: 0.9648:  89%|████████▉ | 8/9 [00:02<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 9, loss: 0.2663, acc: 0.9661: 100%|██████████| 9/9 [00:02<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 9, loss: 1.2710, acc: 0.5676: 100%|██████████| 1250/1250 [00:10<00:00, 116.56it/s]\n",
            "Test epoch 9, loss: 1.5878, acc: 0.4949: 100%|██████████| 1188/1188 [00:08<00:00, 133.36it/s]\n",
            "Train epoch 10, loss: 0.2339, acc: 0.9785:  11%|█         | 1/9 [00:00<00:02,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2374, acc: 0.9756:  22%|██▏       | 2/9 [00:00<00:01,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2313, acc: 0.9772:  33%|███▎      | 3/9 [00:00<00:01,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2362, acc: 0.9727:  44%|████▍     | 4/9 [00:01<00:01,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2360, acc: 0.9727:  56%|█████▌    | 5/9 [00:01<00:01,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2375, acc: 0.9736:  67%|██████▋   | 6/9 [00:01<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2398, acc: 0.9738:  78%|███████▊  | 7/9 [00:01<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2373, acc: 0.9761:  89%|████████▉ | 8/9 [00:02<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 10, loss: 0.2362, acc: 0.9770: 100%|██████████| 9/9 [00:02<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 10, loss: 1.2646, acc: 0.5704: 100%|██████████| 1250/1250 [00:10<00:00, 120.35it/s]\n",
            "Test epoch 10, loss: 1.5862, acc: 0.4924: 100%|██████████| 1188/1188 [00:08<00:00, 134.68it/s]\n",
            "Train epoch 11, loss: 0.2192, acc: 0.9863:  11%|█         | 1/9 [00:00<00:02,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2251, acc: 0.9814:  22%|██▏       | 2/9 [00:00<00:01,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2218, acc: 0.9818:  33%|███▎      | 3/9 [00:00<00:01,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2281, acc: 0.9766:  44%|████▍     | 4/9 [00:01<00:01,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2291, acc: 0.9758:  56%|█████▌    | 5/9 [00:01<00:01,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2313, acc: 0.9762:  67%|██████▋   | 6/9 [00:01<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2340, acc: 0.9760:  78%|███████▊  | 7/9 [00:01<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2318, acc: 0.9780:  89%|████████▉ | 8/9 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 11, loss: 0.2309, acc: 0.9789: 100%|██████████| 9/9 [00:02<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 11, loss: 1.2671, acc: 0.5702: 100%|██████████| 1250/1250 [00:10<00:00, 120.24it/s]\n",
            "Test epoch 11, loss: 1.5905, acc: 0.4937: 100%|██████████| 1188/1188 [00:09<00:00, 128.24it/s]\n",
            "Train epoch 12, loss: 0.2154, acc: 0.9863:  11%|█         | 1/9 [00:00<00:02,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2208, acc: 0.9814:  22%|██▏       | 2/9 [00:00<00:01,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2186, acc: 0.9818:  33%|███▎      | 3/9 [00:00<00:01,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2258, acc: 0.9766:  44%|████▍     | 4/9 [00:01<00:01,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2267, acc: 0.9754:  56%|█████▌    | 5/9 [00:01<00:01,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2278, acc: 0.9759:  67%|██████▋   | 6/9 [00:01<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2294, acc: 0.9760:  78%|███████▊  | 7/9 [00:01<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2271, acc: 0.9778:  89%|████████▉ | 8/9 [00:02<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 12, loss: 0.2257, acc: 0.9787: 100%|██████████| 9/9 [00:02<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 12, loss: 1.2757, acc: 0.5706: 100%|██████████| 1250/1250 [00:10<00:00, 120.08it/s]\n",
            "Test epoch 12, loss: 1.6041, acc: 0.4904: 100%|██████████| 1188/1188 [00:08<00:00, 139.71it/s]\n",
            "Train epoch 13, loss: 0.2029, acc: 0.9863:  11%|█         | 1/9 [00:00<00:02,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2055, acc: 0.9863:  22%|██▏       | 2/9 [00:00<00:01,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2043, acc: 0.9850:  33%|███▎      | 3/9 [00:00<00:01,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2100, acc: 0.9805:  44%|████▍     | 4/9 [00:01<00:01,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2089, acc: 0.9801:  56%|█████▌    | 5/9 [00:01<00:01,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2089, acc: 0.9811:  67%|██████▋   | 6/9 [00:01<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2097, acc: 0.9816:  78%|███████▊  | 7/9 [00:01<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2070, acc: 0.9829:  89%|████████▉ | 8/9 [00:02<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 13, loss: 0.2042, acc: 0.9837: 100%|██████████| 9/9 [00:02<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 13, loss: 1.3310, acc: 0.5608: 100%|██████████| 1250/1250 [00:10<00:00, 119.20it/s]\n",
            "Test epoch 13, loss: 1.6747, acc: 0.4843: 100%|██████████| 1188/1188 [00:08<00:00, 135.53it/s]\n",
            "Train epoch 14, loss: 0.1684, acc: 0.9980:  11%|█         | 1/9 [00:00<00:02,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1701, acc: 0.9951:  22%|██▏       | 2/9 [00:00<00:01,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1682, acc: 0.9948:  33%|███▎      | 3/9 [00:00<00:01,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1681, acc: 0.9941:  44%|████▍     | 4/9 [00:01<00:01,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1656, acc: 0.9930:  56%|█████▌    | 5/9 [00:01<00:01,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1650, acc: 0.9932:  67%|██████▋   | 6/9 [00:01<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1633, acc: 0.9933:  78%|███████▊  | 7/9 [00:01<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1592, acc: 0.9939:  89%|████████▉ | 8/9 [00:02<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 14, loss: 0.1558, acc: 0.9941: 100%|██████████| 9/9 [00:02<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 14, loss: 1.3938, acc: 0.5594: 100%|██████████| 1250/1250 [00:10<00:00, 120.85it/s]\n",
            "Test epoch 14, loss: 1.7617, acc: 0.4834: 100%|██████████| 1188/1188 [00:08<00:00, 136.42it/s]\n",
            "Train epoch 15, loss: 0.1146, acc: 1.0000:  11%|█         | 1/9 [00:00<00:02,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1127, acc: 1.0000:  22%|██▏       | 2/9 [00:00<00:01,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1092, acc: 0.9993:  33%|███▎      | 3/9 [00:00<00:01,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1071, acc: 0.9990:  44%|████▍     | 4/9 [00:01<00:01,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1045, acc: 0.9992:  56%|█████▌    | 5/9 [00:01<00:01,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1026, acc: 0.9993:  67%|██████▋   | 6/9 [00:01<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.1004, acc: 0.9994:  78%|███████▊  | 7/9 [00:01<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.0970, acc: 0.9995:  89%|████████▉ | 8/9 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 15, loss: 0.0940, acc: 0.9996: 100%|██████████| 9/9 [00:02<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 15, loss: 1.4466, acc: 0.5615: 100%|██████████| 1250/1250 [00:10<00:00, 119.51it/s]\n",
            "Test epoch 15, loss: 1.8387, acc: 0.4864: 100%|██████████| 1188/1188 [00:08<00:00, 133.77it/s]\n",
            "Train epoch 16, loss: 0.0618, acc: 1.0000:  11%|█         | 1/9 [00:00<00:02,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0596, acc: 1.0000:  22%|██▏       | 2/9 [00:00<00:01,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0569, acc: 1.0000:  33%|███▎      | 3/9 [00:00<00:01,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0551, acc: 1.0000:  44%|████▍     | 4/9 [00:01<00:01,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0533, acc: 1.0000:  56%|█████▌    | 5/9 [00:01<00:01,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0520, acc: 1.0000:  67%|██████▋   | 6/9 [00:01<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0504, acc: 1.0000:  78%|███████▊  | 7/9 [00:01<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0486, acc: 1.0000:  89%|████████▉ | 8/9 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train epoch 16, loss: 0.0469, acc: 1.0000: 100%|██████████| 9/9 [00:02<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_steps 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 16, loss: 1.5258, acc: 0.5624: 100%|██████████| 1250/1250 [00:10<00:00, 121.59it/s]\n",
            "Test epoch 16, loss: 1.9452, acc: 0.4891: 100%|██████████| 1188/1188 [00:08<00:00, 133.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement in validation accuracy for 5 epochs. Early stopping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_accs, label='Training accuracy')\n",
        "plt.plot(val_acc1, label='Validation accuracy1')\n",
        "plt.plot(val_acc2, label='Validation accuracy2')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "inhDiQhLWxp-",
        "outputId": "e0485e0b-4c82-4529-a837-88dc0a76c6cb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6pklEQVR4nO3deZyN5f/H8dc5Z+ac2ccsZjGGsYydsYsWe4NSlEKy07dCSb5JQhQSSeJLyZJ+laWQUsSgbCEau7HvsxjLjFnPzDn374/DMcfszMw9y+f5eNyd+9zb+Zwj57xd93Vft0ZRFAUhhBBCiFJCq3YBQgghhBAFScKNEEIIIUoVCTdCCCGEKFUk3AghhBCiVJFwI4QQQohSRcKNEEIIIUoVCTdCCCGEKFXs1C6gqJnNZq5evYqrqysajUbtcoQQQgiRB4qicPv2bSpUqIBWm3PbTJkLN1evXiUwMFDtMoQQQgjxAC5dukTFihVz3KbMhRtXV1fA8uG4ubmpXI0QQggh8iI+Pp7AwEDr73hOyly4uXsqys3NTcKNEEIIUcLkpUuJdCgWQgghRKki4UYIIYQQpYqEGyGEEEKUKhJuhBBCCFGqSLgRQgghRKki4UYIIYQQpYqEGyGEEEKUKhJuhBBCCFGqSLgRQgghRKki4UYIIYQQpYqq4eavv/6ia9euVKhQAY1Gw9q1a3PdZ9u2bTRu3BiDwUD16tVZunRpodcphBBCiJJD1XCTmJhISEgI8+bNy9P2586d46mnnqJt27aEh4czcuRIhgwZwsaNGwu5UiGEEEKUFKreOLNz58507tw5z9svWLCAKlWq8OmnnwJQu3ZtduzYwWeffUZoaGhhlSmEEEKUeoqiYFbuPZoVBbA8ZlyuKArKnfXKnfWKgnWZWVHQ67T4uDmo9l5K1F3Bd+/eTYcOHWyWhYaGMnLkyGz3SU1NJTU11fo8Pj6+sMoTQgghClVquombiWlcT0zlRqKRG4lGricYuZlk5HqikRsJd5YlpnIrKY00k9kSPLgXPDIGkYzhpCA1qezBT6+1KtiD5kOJCjdRUVH4+vraLPP19SU+Pp7k5GQcHR0z7TNt2jQmTZpUVCUKIYQQeaIoColGkyWQJBm5kZjK9TvhJON0PcN8Qmq62mVnotGAVqNBqwGNRoMGsNdpVK2pRIWbBzF27FhGjRplfR4fH09gYKCKFQkhhCjtUtNNXLiexJmYBM7GJhKbkJplaDGmm/N9bJ1Wg4eTHk9nezyd9Xg5G/B01uPhrMfLWX9nmeW53k6LhrvhQ4NGcy+MZHzUYAkn97a5F1buLgfbEHP3sTgqUeHGz8+P6Ohom2XR0dG4ubll2WoDYDAYMBgMRVGeEEKIMuZGopEz1xI4E5NgebyWyNlrCVy8kYQ5j6d6DHZaSyhx0ePpbLAEEyc9Xi6WoJIxrHg563FzsEerLZ6horgoUeGmZcuW/PbbbzbLNm3aRMuWLVWqSAghRGmXbjJz6WbynVaYBM7EJN4JMgncTErLdj9Xgx1VfVyo5u2Mj5uDtVUl4+TlosdJX6J+iksEVT/RhIQETp8+bX1+7tw5wsPD8fT0pFKlSowdO5YrV66wbNkyAF599VXmzp3LO++8w6BBg9iyZQsrV65k/fr1ar0FIYQQpcTtlDTOXrsXXO6GmPPXE0kzZd8ME1DOkWo+LlQr70y18i6WyceZ8i6GYnvaprRTNdz8888/tG3b1vr8bt+Y/v37s3TpUiIjI7l48aJ1fZUqVVi/fj1vvfUWn3/+ORUrVuTrr7+Wy8CFEELkidmsEBmfkuE00r0QE3M7Ndv9HOy1VPV2sQkxVcs7U9XbBUe9rgjfgcgLjaIU9AVgxVt8fDzu7u7ExcXh5uamdjlCCCEegqIoJKSmcyspjZtJRm4mpXEz0Widv5XhMTbByPnYRJLTTNkez8fVYA0ulhYYS5ip4O4o/VxUlp/fbznRJ4QQolhIN5m5lXwvkNxMNNqElltJlquMMi6LSzbmeMooK/Y6DZW9nO87jWQJNG4O9oX07kRRknAjhBDFXLrJjNFkJjUt46OJlLT7l5tyfG5MN5NqnUzWUKDBcnnwvXnLWCXcuUSYO+s11kfNve3vbJhx/Z0lGZbda/HQaCwDyMUl24aWm4lG4lMefAwXg50WT2c95Zz0eDjZ4+Gkp9ydRw/nO8uc9QR5ORPo4YidTu4bXZpJuBFCiCKUZjJz4Xoip2MSOBWdwKmYBC7fTCIlzRI4MocYM6a8XlNcSrg52OGRRVDxdNJTzjmL8OKkl34vwoaEGyGEKAQpaSbOXEvgdMy96VRMAudjE0l/iLCi1YDBTofBXotep733aKdDb6dFb6fFYJ101ue2j5bl9ndaLzJ2vbQM1a9Yh+y/f1nG7e9uk2n9nZUZ12XcXgO4O2YIKHcCSzknPeUc7aVVRTw0CTdCCPEQbqekceZaIqeib3P6WgKn77TGXLqZlO39epz1Oqr7WPp5BPu4EuTlhJPBziasONhr0esyhxj54RcidxJuhBAiD24kGu+0vty2aY2JjEvJdp9yTvYE+7hQ3ceF6j6uVPdxIdjHBX93Bxn/RIhCJOFGCCHuUBSFmNupnIpO4HTMbU5lCDHXE43Z7ufjarAGl7tBJtjXBS9nvYQYIVQg4UYIUabFp6Sx5XgMvx2OZPfZ69zO4Yqdih6OmUJMdR8X3B3l8mEhihMJN0KIMicuKY1Nx6P5/XAk20/FYjTduzOzTquhsqfTnfDiQrCvC9XLu1LNx1nuASRECSF/U4UQZcKNRCObjkXx2+Eodp6OtbliqVp5Z56q70/HOn7U8HPBYCeXFQtRkkm4EUKUWtdup/LHsSh+PxzF7rPXbcaLqeXnSud6/nSp70ewr6uKVQohCpqEGyFEqRIdn8KGI1H8djiSfedvkHFImboV3OhS359O9fyoVt5FvSKFEIVKwo0QosS7eiuZ349E8fvhSPZfvGkzvkxIRXc61/encz0/Kns5q1ekEKLISLgRQpRIl24k8fuRSH47HEX4pVs26xpXKkeX+v6E1vUj0NNJnQKFEKqRcCOEKDHOxyby25FIfj8cxeErcdblGg00q+xJ5/p+dKrnh7+7o4pVCiHUJuFGCFGsnY5J4PfDkfx2JIrjkfHW5VoNtKjiRZf6foTW9cPHzUHFKoUQxYmEGyFEsaIoCiejE/jtcCS/H4nkZHSCdZ1Oq6FVNS861/Pnybq+eLsYVKxUCFFcSbgRQhQLZrPCpuPR/G/raQ5evnfKyV6n4dHq3nSp50/HOr54OOtVrFIIURJIuBFCqCrdZOaXQ1f539YznIqxtNLodVqeqOFN53r+dKjti7uT3N5ACJF3Em6EEKpISTPx04HLLPjzDJduJAPgarCjX6vKDHy0ipxyEkI8MAk3QogilZiazvd7LrJw+1libqcC4OmsZ/BjVXj5kcpyE0ohxEOTcCOEKBK3kows3XWepbvOcyspDQB/dwdeeaIqvZpVwlEv93MSQhQMCTdCiEIVE5/Coh3n+L+/L5BoNAEQ5OXEa22q0b1RRfR2WpUrFEKUNhJuhBCF4tKNJL786wwr/7mMMd0MWG5WOaxtdbrU90en1ahcoRCitJJwI4QoUKdjbvO/rWf4+eBV6124G1cqx/B21Wlb0weNRkKNEKJwSbgRQhSIQ5dv8b+tZ9h4LMp648rHg715vU11HqnqKaFGCFFkJNwIIR6YoijsOXeDeVtPs/1UrHV5aF1fXm9TnZDAcuoVJ4QosyTcCCHyTVEUtkVcY97W0/xz4SZguTXCMyEVeK1NNWr4uqpcoRCiLJNwI4TIM5NZ4fcjkczbesZ6E0u9TssLTSvynyeqUcnLSeUKhRBCwo0QIg+M6WbW/nuF+X+e4VxsIgBOeh0vP1KZwY9VwVfuyC2EKEYk3AghspVsNLFi30W++ussV+NSAHB3tGdAqyAGtAqSm1gKIYolCTdCiCwt33uRGRsjuJ5oBKC8q4Ghj1fhpRaVcTHIV4cQoviSbyghhA2zWWHa78dZuP0cABU9HHm1dTV6NKmIg73cIkEIUfxJuBFCWKWkmXh71UHWH4oE4O2ONXi1TTXsdXKLBCFEyaH6N9a8efMICgrCwcGBFi1asHfv3my3TUtLY/LkyVSrVg0HBwdCQkLYsGFDEVYrROl1K8lIv0V7WX8oEnudhtk9GzKifbAEGyFEiaPqt9aKFSsYNWoUEydO5MCBA4SEhBAaGkpMTEyW27///vt8+eWXfPHFFxw7doxXX32V7t278++//xZx5UKULpduJPH8/F3sPX8DV4Md3wxsTrdGAWqXJYQQD0SjKHcHSi96LVq0oFmzZsydOxcAs9lMYGAgI0aM4N133820fYUKFRg3bhzDhg2zLnv++edxdHTk//7v//L0mvHx8bi7uxMXF4ebm1vBvBEhSrAjV+IYuHQf126n4u/uwNKBzanpJ4PwCSGKl/z8fqvWcmM0Gtm/fz8dOnS4V4xWS4cOHdi9e3eW+6SmpuLgYDuehqOjIzt27Mj2dVJTU4mPj7eZhBAWWyNiePHL3Vy7nUotP1fWvP6oBBshRImnWriJjY3FZDLh6+trs9zX15eoqKgs9wkNDWXWrFmcOnUKs9nMpk2bWL16NZGRkdm+zrRp03B3d7dOgYGBBfo+hCiplu+9yJBv/iHJaOKx6t6serUlfu4yGJ8QouQrUT0FP//8c4KDg6lVqxZ6vZ7hw4czcOBAtNrs38bYsWOJi4uzTpcuXSrCioUofhRFYdYfEby7+jAms8JzjQNYPKAZrg72apcmhBAFQrVw4+3tjU6nIzo62mZ5dHQ0fn5+We5Tvnx51q5dS2JiIhcuXODEiRO4uLhQtWrVbF/HYDDg5uZmMwlRVhnTzYxedYg5W04D8Ea76nz6Qgh6uxL17xwhhMiRat9oer2eJk2aEBYWZl1mNpsJCwujZcuWOe7r4OBAQEAA6enp/PTTTzz77LOFXa4QJd7tlDQGLd3HTwcuo9NqmPZcfUY9WRONRqN2aUIIUaBUHcRv1KhR9O/fn6ZNm9K8eXNmz55NYmIiAwcOBKBfv34EBAQwbdo0APbs2cOVK1do2LAhV65c4YMPPsBsNvPOO++o+TaEKPai4lIYsGQvJ6Ju46TXMe+lxrSt5aN2WUIIUShUDTc9e/bk2rVrTJgwgaioKBo2bMiGDRusnYwvXrxo058mJSWF999/n7Nnz+Li4kKXLl349ttvKVeunErvQIji72T0bQYs3svVuBS8XQwsGdCM+hXd1S5LCCEKjarj3KhBxrkRZcmuM7H859v93E5Jp2p5Z74Z2JxATye1yxJCiHzLz++33FtKiFLq5/ArjF51kDSTQrMgDxb2a0o5J73aZQkhRKGTcCNEKaMoCvP/PMMnGyIAeKq+P5++GCJ39BZClBkSboQoRdJNZj745Sj/9/dFAIY8VoX3utRGq5UrooQQZYeEGyFKiSRjOm/88C+bj8eg0cCEp+sw8NEqapclhBBFTsKNEKVAbEIqg5fu4+DlOAx2Wj7v1ZBO9fzVLksIIVQh4UaIEu7stQQGLNnHxRtJeDjZ83X/pjSp7Kl2WUIIoRoJN0KUYPsv3GDIN/9wMymNSp5OLB3YjKrlXdQuSwghVCXhRogSasORKN5c/i+p6WZCKrqzaEAzvF0MapclhBCqk3AjRAm0ZOc5Jv96DEWB9rV8+OKlRjjp5a+zEEKAhBshShSzWWHqb8f5esc5APq0qMSkZ+pip5O7egshxF0SboQoIVLSTLy98iDrD0cC8E6nmrzWuprc1VsIIe4j4UaIEuBWkpGhy/5h3/mb2Os0zOgRQrdGAWqXJYQQxZKEGyGKuUs3khiwZC9nriXiarDjy75NaFXdW+2yhBCi2JJwI0QxdiPRSK+v/ubKrWT83R1YOrA5Nf1c1S5LCCGKNQk3QhRTJrPCm8v/5cqtZIK8nFj+Skv83B3ULksIIYo9ucRCiGLq880n2X4qFgd7LQv6NpFgI4QQeSThRohiaMuJaOZsOQ3Ax881oJafm8oVCSFEySHhRohi5uL1JEYuDwegX8vKclWUEELkk4QbIYqRlDQTr/7ffuJT0mlUqRzvP1VH7ZKEEKLEkXAjRDGhKArj1x7hWGQ8Xs56/tenMXo7+SsqhBD5Jd+cQhQTy/ddYtX+y2g18EXvRvi7O6pdkhBClEgSboQoBg5dvsXEn48CMDq0pgzSJ4QQD0HCjRAqu5lo5LX/O4DRZKZjHV9ea11N7ZKEEKJEk3AjhIpMZoU3V4RbB+r79MUQuRGmEEI8JAk3Qqjo87BT/HXyGg72Wua/3AQ3B3u1SxJCiBJPwo0QKtlyIpo5YacAmPZcfWr7y0B9QghRECTcCKGCjAP19X2kMt0bVVS3ICGEKEUk3AhRxO4fqG/80zJQnxBCFCQJN0IUIRmoTwghCp98qwpRhGSgPiGEKHwSboQoIjJQnxBCFA0JN0IUARmoTwghio6EGyEKmQzUJ4QQRUvCjRCFTAbqE0KIoqV6uJk3bx5BQUE4ODjQokUL9u7dm+P2s2fPpmbNmjg6OhIYGMhbb71FSkpKEVUrRP5sPREjA/UJIUQRUzXcrFixglGjRjFx4kQOHDhASEgIoaGhxMTEZLn9999/z7vvvsvEiRM5fvw4ixYtYsWKFbz33ntFXLkQubt0I4mRK8IBGahPCCGKkqrhZtasWQwdOpSBAwdSp04dFixYgJOTE4sXL85y+127dvHoo4/y0ksvERQUxJNPPknv3r1zbe0RoqjdHagvLjmNhoHleP/p2mqXJIQQZYZq4cZoNLJ//346dOhwrxitlg4dOrB79+4s92nVqhX79++3hpmzZ8/y22+/0aVLl2xfJzU1lfj4eJtJiMJ0d6C+o1fj8bwzUJ/BTqd2WUIIUWbYqfXCsbGxmEwmfH19bZb7+vpy4sSJLPd56aWXiI2N5bHHHkNRFNLT03n11VdzPC01bdo0Jk2aVKC1C5GT+wfqq1BOBuoTQoiipHqH4vzYtm0bU6dO5X//+x8HDhxg9erVrF+/ng8//DDbfcaOHUtcXJx1unTpUhFWLMqajAP1vf1kTR6VgfqEEKLIqdZy4+3tjU6nIzo62mZ5dHQ0fn5+We4zfvx4+vbty5AhQwCoX78+iYmJvPLKK4wbNw6tNnNWMxgMGAyGgn8DQtwn40B9HWrLQH1CCKEW1Vpu9Ho9TZo0ISwszLrMbDYTFhZGy5Yts9wnKSkpU4DR6Sx9GRRFKbxihchFxoH6Kt8ZqE+rlYH6hBBCDaq13ACMGjWK/v3707RpU5o3b87s2bNJTExk4MCBAPTr14+AgACmTZsGQNeuXZk1axaNGjWiRYsWnD59mvHjx9O1a1dryBFCDRkH6lvwchPcHWWgPiGEUIuq4aZnz55cu3aNCRMmEBUVRcOGDdmwYYO1k/HFixdtWmref/99NBoN77//PleuXKF8+fJ07dqVKVOmqPUWhLAZqG9qdxmoTwgh1KZRytj5nPj4eNzd3YmLi8PNTX6ExMO5dCOJp7/YQVxyGi8/UomPutVXuyQhhCiV8vP7XaKulhKiOLl/oL7xT9dRuyQhhBBIuBHigU34WQbqE0KI4kjCjRAPYPnei6z8RwbqE0KI4kjCjRD5dPhyHBPWyUB9QghRXEm4ESIfbiYaefX/9mNMl4H6hBCiuJJwI0QeyUB9QghRMki4ESKP5shAfUIIUSJIuBEiD/69eJMvtshAfUIIURJIuBEiF6npJt758RBmBbo1rMBzjSuqXZIQQogcSLgRIhdzt5zmVEwC3i56Jnatq3Y5QgghciHhRogcHL0ax/+2nQHgw2fr4eGsV7kiIYQQuZFwI0Q20kxm3vnxECazQud6fnSu7692SUIIIfJAwo0Q2fjqr7McvRpPOSd7Jj0rp6OEEKKkkHAjRBZORd/m882Wq6Mmdq2Dj6uDyhUJIYTIKwk3QtzHZFb474+HMJrMtKvlQ7eGAWqXJIQQIh8k3AhxnyU7zxF+6RauBjumdK+HRiOjEAshREki4UaIDM7HJjLzjwgA3nuqNv7ucrdvIYQoaSTcCHGH2aww5qdDpKSZebS6F72aBapdkhBCiAcg4UaIO77be5E9527gaK/j4+cayOkoIYQooSTcCAFcuZXMx78dB+CdTjUJ9HRSuSIhhBAPSsKNKPMURWHs6sMkGk00rexB/5ZBapckhBDiIUi4EWXej/sv89fJa+jttEzv0QCtVk5HCSFESSbhRpRpMfEpfPjrMQDe6lCDauVdVK5ICCHEw5JwI8osRVEYt/YI8Snp1A9wZ+jjVdQuSQghRAGQcCPKrF8PRbLpWDT2Og0zXmiAnU7+OgghRGkg3+aiTLqekMrEdUcBGNa2OrX83FSuSAghREGRcCPKpA9+OcaNRCO1/Fx5vU11tcsRQghRgCTciDLnj6NR/HLwKloNfNKjAXo7+WsghBCliXyrizIlLimN99ceAeCVJ6rRoGI5dQsSQghR4CTciDLlo/XHiLmdStXyzozsEKx2OUIIIQqBhBtRZvx18hqr9l9Go4FPnm+Ag71O7ZKEEEIUAgk3okxISE1n7OrDAPRvGUTTIE+VKxJCCFFYJNyIMmH67ye4ciuZQE9H3ulUU+1yhBBCFCIJN6LU+/vsdb79+wIAHz/XACe9ncoVCSGEKEzFItzMmzePoKAgHBwcaNGiBXv37s122zZt2qDRaDJNTz31VBFWLEqKZKOJd386BEDv5oE8Wt1b5YqEEEIUNtXDzYoVKxg1ahQTJ07kwIEDhISEEBoaSkxMTJbbr169msjISOt05MgRdDodL7zwQhFXLkqCWZsiOH89CT83B8Z2qa12OUIIIYqA6uFm1qxZDB06lIEDB1KnTh0WLFiAk5MTixcvznJ7T09P/Pz8rNOmTZtwcnKScCMyOXDxJot2nANg6nP1cHOwV7kiIYQQRUHVcGM0Gtm/fz8dOnSwLtNqtXTo0IHdu3fn6RiLFi2iV69eODs7Z7k+NTWV+Ph4m0mUfqnpJt758RBmBbo3CqBdLV+1SxJCCFFEVA03sbGxmEwmfH1tf3h8fX2JiorKdf+9e/dy5MgRhgwZku0206ZNw93d3ToFBgY+dN2i+Ju75TSnYxLwdtEz4ek6apcjhBCiCKl+WuphLFq0iPr169O8efNstxk7dixxcXHW6dKlS0VYoVDDkStx/G/bGQA+fLYeHs56lSsSQghRlFS9Jtbb2xudTkd0dLTN8ujoaPz8/HLcNzExkeXLlzN58uQctzMYDBgMhoeuVZQMaSYz7/x4CJNZoUt9PzrX91e7JCGEEEVM1ZYbvV5PkyZNCAsLsy4zm82EhYXRsmXLHPddtWoVqampvPzyy4VdpihBvvzzDMci4ynnZM+kZ+qpXY4QQggVqD6a2ahRo+jfvz9NmzalefPmzJ49m8TERAYOHAhAv379CAgIYNq0aTb7LVq0iG7duuHl5aVG2aIYOhV9mzlhpwGY2LUO5V2lxU4IIcqifIeboKAgBg0axIABA6hUqdJDF9CzZ0+uXbvGhAkTiIqKomHDhmzYsMHayfjixYtotbYNTBEREezYsYM//vjjoV9flA4ms8J/fzyE0WSmXS0fujUMULskIYQQKtEoiqLkZ4fZs2ezdOlSjhw5Qtu2bRk8eDDdu3cvMf1a4uPjcXd3Jy4uDjc3N7XLEQXk6+1n+Wj9cVwNdvwx6gn83R3VLkkIIUQBys/vd7773IwcOZLw8HD27t1L7dq1GTFiBP7+/gwfPpwDBw48cNFCPKjzsYnM2BgBwHtP1ZZgI4QQZdwDdyhu3Lgxc+bM4erVq0ycOJGvv/6aZs2a0bBhQxYvXkw+G4SEeCBms8KYnw6Rmm7m0epe9Gom4xgJIURZ98AditPS0lizZg1Llixh06ZNPPLIIwwePJjLly/z3nvvsXnzZr7//vuCrFWITL7be5E9527gaK/j4+caoNFo1C5JCCGEyvIdbg4cOMCSJUv44Ycf0Gq19OvXj88++4xatWpZt+nevTvNmjUr0EKFuN/lm0l8/NtxAMZ0qkmgp5PKFQkhhCgO8h1umjVrRseOHZk/fz7dunXD3j7zzQirVKlCr169CqRAIbKiKApjVx8m0WiiaWUP+rUMUrskIYQQxUS+w83Zs2epXLlyjts4OzuzZMmSBy5KiNz8uP8y20/ForfTMr1HA7RaOR0lhBDCIt8dimNiYtizZ0+m5Xv27OGff/4pkKKEyEl0fAof/noMgFEda1CtvIvKFQkhhChO8h1uhg0bluXNJ69cucKwYcMKpCghsqMoCu+vPUJ8SjoNKroz5LEqapckhBCimMl3uDl27BiNGzfOtLxRo0YcO3asQIoSIju/HY5i07Fo7HUaPunRADtdib6xvRBCiEKQ718Gg8GQ6S7eAJGRkdjZqX6rKlGKxSWlMXHdUQBea12NWn4ywrQQQojM8h1unnzyScaOHUtcXJx12a1bt3jvvffo2LFjgRYnREbTfj9ObEIqVcs783rb6mqXI4QQopjKd1PLzJkzeeKJJ6hcuTKNGjUCIDw8HF9fX7799tsCL1AIgL/PXmf5Pktfr4+fa4CDvU7lioQQQhRX+Q43AQEBHDp0iO+++46DBw/i6OjIwIED6d27d5Zj3gjxsFLSTIxdfRiAl1pUonkVT5UrEkIIUZw9UCcZZ2dnXnnllYKuRYgsfbHlFOdiE/FxNfBu51q57yCEEKJMe+AewMeOHePixYsYjUab5c8888xDFyXEXccj4/nyz7MATH62Lm4O0joohBAiZw80QnH37t05fPgwGo3GevfvuzcsNJlMBVuhKLNMZoV3Vx8m3azwZB1fOtXzV7skIYQQJUC+r5Z68803qVKlCjExMTg5OXH06FH++usvmjZtyrZt2wqhRFFWLdt9noOXbuFqsGPys/XULkcIIUQJke+Wm927d7Nlyxa8vb3RarVotVoee+wxpk2bxhtvvMG///5bGHWKMubKrWRmbIwAYEznWvi5O6hckRBCiJIi3y03JpMJV1dXALy9vbl69SoAlStXJiIiomCrE2WSoii8v+YwSUYTzYI8eKl5JbVLEkIIUYLku+WmXr16HDx4kCpVqtCiRQs++eQT9Ho9X331FVWrVi2MGkUZ88uhSLZGXEOv0zLtufpyx28hhBD5ku9w8/7775OYmAjA5MmTefrpp3n88cfx8vJixYoVBV6gKFtuJRmZ/IvlFgvD2lanuo+ryhUJIYQoafIdbkJDQ63z1atX58SJE9y4cQMPDw/rFVNCPKgp648Tm2Ak2MeF19pUU7scIYQQJVC++tykpaVhZ2fHkSNHbJZ7enpKsBEPbefpWFbtv4xGAx8/Xx+9ndzxWwghRP7l69fD3t6eSpUqyVg2osClpJl4b43lFgsvt6hMk8pyiwUhhBAPJt//NB43bhzvvfceN27cKIx6RBk1e/MpLlxPws/NgXc61VS7HCGEECVYvvvczJ07l9OnT1OhQgUqV66Ms7OzzfoDBw4UWHGibDh6NY6F2y23WPiwWz1c5RYLQgghHkK+w023bt0KoQxRVpnMCmNXH8ZkVuhS34+OdXzVLkkIIUQJl+9wM3HixMKoQ5RRS3ae49DlOFwd7Piga121yxFCCFEKyOUoQjWXbiTx6R8nAXivS2183OQWC0IIIR5evltutFptjpd9y5VUIi8URWHc2iMkp5loUcWTnk0D1S5JCCFEKZHvcLNmzRqb52lpafz777988803TJo0qcAKE6Xbz+FX+evkNfR2cosFIYQQBSvf4ebZZ5/NtKxHjx7UrVuXFStWMHjw4AIpTJReNxKNTP71GABvtKtO1fIuKlckhBCiNCmwPjePPPIIYWFhBXU4UYp9tP4YNxKN1PR15ZUn5BYLQgghClaBhJvk5GTmzJlDQEBAQRxOlGJ/nbzG6gNX5BYLQgghCk2+f1k8PDzw9PS0Th4eHri6urJ48WJmzJiR7wLmzZtHUFAQDg4OtGjRgr179+a4/a1btxg2bBj+/v4YDAZq1KjBb7/9lu/XFUUvyZjOuLWWWyz0bxlEo0oeKlckhBCiNMp3n5vPPvvM5moprVZL+fLladGiBR4e+fuxWrFiBaNGjWLBggW0aNGC2bNnExoaSkREBD4+Ppm2NxqNdOzYER8fH3788UcCAgK4cOEC5cqVy+/bECqYvfkUl24kU8HdgdGhcosFIYQQhUOjKIqi1ou3aNGCZs2aMXfuXADMZjOBgYGMGDGCd999N9P2CxYsYMaMGZw4cQJ7+wcboj8+Ph53d3fi4uJwc3N7qPpF3h25Esczc3dgVmDxgKa0qyUjEQshhMi7/Px+5/u01JIlS1i1alWm5atWreKbb77J83GMRiP79++nQ4cO94rRaunQoQO7d+/Ocp9169bRsmVLhg0bhq+vL/Xq1WPq1Kk5jq2TmppKfHy8zSSKVrrJzJifDmFW4OkG/hJshBBCFKp8h5tp06bh7e2dabmPjw9Tp07N83FiY2MxmUz4+tr+0Pn6+hIVFZXlPmfPnuXHH3/EZDLx22+/MX78eD799FM++uijHOt1d3e3ToGBMlhcUVu04xxHr8bj7mjPRLnFghBCiEKW73Bz8eJFqlSpkml55cqVuXjxYoEUlR2z2YyPjw9fffUVTZo0oWfPnowbN44FCxZku8/YsWOJi4uzTpcuXSrUGoWti9eT+Gyz5RYL456qTXlXg8oVCSGEKO3y3aHYx8eHQ4cOERQUZLP84MGDeHl55fk43t7e6HQ6oqOjbZZHR0fj5+eX5T7+/v7Y29uj0+msy2rXrk1UVBRGoxG9Xp9pH4PBgMEgP6hqUBSF99YcJiXNTKtqXrzQpKLaJQkhhCgD8t1y07t3b9544w22bt2KyWTCZDKxZcsW3nzzTXr16pXn4+j1epo0aWIz8J/ZbCYsLIyWLVtmuc+jjz7K6dOnMZvN1mUnT57E398/y2Aj1LX6wBV2nI7FYKdlavf6Od6TTAghhCgo+Q43H374IS1atKB9+/Y4Ojri6OjIk08+Sbt27fLV5wZg1KhRLFy4kG+++Ybjx4/z2muvkZiYyMCBAwHo168fY8eOtW7/2muvcePGDd58801OnjzJ+vXrmTp1KsOGDcvv2xCFLDYhlQ/XW26x8GaHYIK8nVWuSAghRFmR79NSer2eFStW8NFHHxEeHo6joyP169encuXK+X7xnj17cu3aNSZMmEBUVBQNGzZkw4YN1k7GFy9eRKu9l78CAwPZuHEjb731Fg0aNCAgIIA333yTMWPG5Pu1ReH68Ndj3EpKo7a/G0Mfr6p2OUIIIcoQVce5UYOMc1P4tkbEMHDJPrQaWDvsURpULKd2SUIIIUq4Qh3n5vnnn2f69OmZln/yySe88MIL+T2cKGUSU9N5f80RAAY+WkWCjRBCiCKX73Dz119/0aVLl0zLO3fuzF9//VUgRYmSa9amk1y5lUxAOUdGdayhdjlCCCHKoHyHm4SEhCyvTLK3t5fRf8u4g5dusWTnOQCmdK+HsyHfXbqEEEKIh5bvcFO/fn1WrFiRafny5cupU6dOgRQlSp60DLdY6NawAm1qZr7xqRBCCFEU8v1P6/Hjx/Pcc89x5swZ2rVrB0BYWBjff/89P/74Y4EXKEqGhdvPciLqNh5O9ox/WkKuEEII9eQ73HTt2pW1a9cydepUfvzxRxwdHQkJCWHLli14enoWRo2imDsfm8jnm08B8P5TdfBykRGhRSlmNkNa0r3JePcxEdKSIS3xzrKM8xm3zWJ9eqrl2Brrf0CjscxbB7/U3FuW23qbZbkcEwUUMyjKncl837Lsnuewvc0yMm+j0UK5SuBVzTJ5VgOv6pZ5F98M9QnxYB76UvD4+Hh++OEHFi1axP79+3O8Q3dxIJeCFyxFUejz9R52nbnO48HeLBvUXEYiFsVXeiok3YCk65B85zHphmVKvgHJt2wDiTWwZJhPT1b7XZRuehfwrHov7HhVt0yeVcFJ/gFdluXn9/uBe3z+9ddfLFq0iJ9++okKFSrw3HPPMW/evAc9nCihVu2/zK4z13Gw1zKlm9xiQRShtOTsg0p24cWYULA12DtZJr1ThnnnO/OO9+Zt1mexrZ1DhoPeaRGxPt63DHJen+0+ZL1eo7W0lGg0lnk0GZbl9Jz7nue0D7bPTWlw8zxcPwPXT8ONO4+3Llr+jKIOWab7OXreCzye1WxbfgwuD/EHKUqbfIWbqKgoli5dyqJFi4iPj+fFF18kNTWVtWvXSmfiMuja7VSmrD8OwKiONajk5aRyRaJUuHkeLv+TIZhkE1TSkh7s+BqdpQXA0ROcvCzzd587lrO0HGQZSJxtA4u9o5w+eRhe1aB6e9tl6UbLn//dsHM9w+Ptq5Y/98s34PK+zMdz8bvTylM1Q2tPNfCsAnZyqjxHZjMoJjCng/nOo2K+77npznzG5+mWfW3W35k3uEFgc9XeUp7DTdeuXfnrr7946qmnmD17Np06dUKn07FgwYLCrE8UY5N+OUpcchr1AtwY9GgVtcsRJVncZTi6Fo78BFcP5H0/rZ0loFiDisedR6/7wosXON5ZZ3CDDLd1EcWInR7K17BM9zMmwo2zGVp7zt4LPkmxkBBlmS7ssN1PowX3ipaw41HFEk519qC1tzxmOa8HnZ3lUWufw3x2+9tb/t+8P/wqiqXVKj3Fcoo0y8ec1j3APrkGFBPW1r2CFNgCBv9R8MfNozyHm99//5033niD1157jeDg4MKsSZQA/5y/wa+HItFpNXz8XAPsdPJjIfLpdjQc+9kSaC79fW+5RgsVm4Grf4ZgkkUri5MXGFyl9aSs0DuDX33LdL/km3D9bOYWnxtnITXecrrr1sWir1mbIfCYjJawURhBojBpdKDV3Qlrd+czPrez/GPBOn9nvWc1VcvOc7jZsWMHixYtokmTJtSuXZu+ffvSq1evwqxNFFOKojBjYwQALzatSL0Ad5UrEiVG4nU4vs4SaC7svHMVDYAGKreCut2hzrPgIuMkiXxw9ICKTSxTRooCidfuhZ2b5++1ZpiMllaU7OZNaWBOy/u8ksXFNOY767OjM1j6W9k9wKO9Y+7b6QyWliab4GFn+QeEzXOdJaBo79v2bj+pEijfV0slJiayYsUKFi9ezN69ezGZTMyaNYtBgwbh6upaWHUWGLla6uHtPB1Ln6/3oNdp2fbfNlQo56h2SaI4S74FJ9ZbAs3ZbbY/AhWbQd3noG43cKugUoFCFACzOUPoMd4JSnfnTZYWHJvgoZfTo/mUn9/vh7oUPCIigkWLFvHtt99y69YtOnbsyLp16x70cEVCws3DURSF7v/bRfilWwxoFcQHz9RVuyRRHKXehogNlkBzJszyBX+Xf8idQNMdPCqrV6MQokQpsnBzl8lk4pdffmHx4sUSbkq5sOPRDP7mHxztdfz5Tht8XB1y30mUDcYkOPUHHF0NJzfe6V9wh08dS6Cp95zlKhkhhMinIhnnJiOdTke3bt3o1q1bQRxOFFNms8Knf5wEoH+rIAk2wnJFxukwSwtNxO+WAfDu8qp+L9D41FavRiFEmSO3bRZ5tuFoFMci43E12PGfJ6qqXY5QiykNzv5pCTQn1kNq3L115SrdCzR+DUpsZ0QhRMkm4UbkicmsMGuTpdVm8ONV8HDWq1yRKFJmE5zfYTnldGydZTC1u1wrWPrP1HsOAppIoBFCqE7CjciTn8OvcDomgXJO9gx6TAbsKxPSU+HKAUugOboWEmPurXMuD3W6WQJN4CNy1YcQoliRcCNylWYyM/vOXb//80Q13BzsVa5I5Em6EVLiMky37nue1ZRhm4wdgsEylkjtZyyBpvJjlvEzhBCiGJJvJ5GrH/df5uKNJLxdDPRvJZfuFrnkW5aRV3MNJvdND3rvpYwMblDraUugqdrGMlaHEEIUcxJuRI5S0kzMCbO02gxrWw0nvfwvU+jMJrj6r+UqpDNhlptIZjX6aV4Z3MDBPYupXDbLM0xyHyYhRAkkv1QiRz/svUhkXAr+7g70bl5J7XJKr/hIS5A5HQZnt1rulZORq7/lfkq5hRHHclmEE50qb0kIIdQi4UZkK8mYzrytZwAY0S4YB3v5kSww6alwYdedQLMFYo7arje4QdXWUK09VG9vucRaCCFEnki4Edn6ZtcFYhNSqeTpxAtNK6pdTsmmKJYb99091XR+x319YjRQoZElyFRrDxWbSv8WIYR4QBJuRJbiU9JY8Kel1WZkh2DsddLvIt9S4uDcX/cCza2LtutdfO+1zFRtC85e6tQphBCljIQbkaXFO84Rl5xGtfLOPNswQO1ySgazGSLD751qurTHtiOwTg+VHrkTaDqAb10Z8E4IIQqBhBuRyc1EI4u2nwNgVMea6LTyA5yt29FwZosl0JzZAknXbdd7VrO0zFTvAEGPgd5ZnTqFEKIMkXAjMvnyr7PcTk2ntr8bnev5qV1O8ZJuhEt/W041nQ6D6MO26/WuUOUJqN7O0kLjKaM5CyFEUZNwI2zE3E5h6S5Lq83oJ2uglVYbMCbCyQ1wZDWc2Wp752sA/xBLy0y19hDYXDoCCyGEyiTcCBvzt50hJc1Mw8BytKvlo3Y56klLgdObLIHm5AbbK5ucy9t2BHYpr16dQgghMpFwI6yu3krmu78tV/SMfrImmrLW2TXdaBlA78hqOLEejLfvrfMIgrrPQZ1nwa+BjNorhBDFmIQbYfXFltMYTWYeqerJo9XLyGXJpnQ4/5cl0Bz/xXLjyLvcKkLdbpb7KlVoLFc2CSFECSHhRgBw4Xoiq/65BMDbpb3VxmyCi7stgebYz5AUe2+diy/U6WYJNBWbSwuNEEKUQMXim3vevHkEBQXh4OBAixYt2Lt3b7bbLl26FI1GYzM5ODgUYbWl0+dhp0g3K7SuUZ5mQZ5ql1PwFAUu7YXf34VZdWDpU/DPIkuwcfSEJgOh/y8w6jh0+cQyHo0EGyGEKJFUb7lZsWIFo0aNYsGCBbRo0YLZs2cTGhpKREQEPj5Zd2h1c3MjIiLC+rxUtzIUgdMxt1n77xUA3n6yhsrVFCBFsQyqd2Q1HF0LcRlGCHZwh1pdoV53qNJarnASQohSRPVwM2vWLIYOHcrAgQMBWLBgAevXr2fx4sW8++67We6j0Wjw85PxVwrKZ5tOYVYgtK4vDSqWU7uchxd9DI78BEdXw42z95brXaBmF8spp2rtwM6gXo1CCCEKjarhxmg0sn//fsaOHWtdptVq6dChA7t37852v4SEBCpXrozZbKZx48ZMnTqVunXrZrltamoqqamp1ufx8fEF9wZKgaNX41h/OBKNBt7qWIJbbWJP3WmhWQ3XTtxbbucINUItgSb4SbB3VK9GIYQQRULVcBMbG4vJZMLX19dmua+vLydOnMhyn5o1a7J48WIaNGhAXFwcM2fOpFWrVhw9epSKFTPfuXratGlMmjSpUOovDWb9cRKArg0qUMvPTeVq8unm+XuBJirDSME6PVTvaAk0NTqBwUW1EoUQQhQ91U9L5VfLli1p2bKl9XmrVq2oXbs2X375JR9++GGm7ceOHcuoUaOsz+Pj4wkMDCySWou7AxdvEnYiBp1Ww8gOwWqXk5kpHZJvQOK1O1OsZUqIhnN/wpX997bV2lkG1Kv3HNR6ytKnRghAURRup93mevJ1y5SS+fFG8g2up1wnIS0Bg9aAg52DZdI5WOcNOgOOdo446Bww2Blw0DngaOeIQWfZPtt5naNl+zvzdlq7B+4nqCgKJsWESTGRbk4n3ZxOmjmNdHO6zbKM67JcrqRhMpswK2Yc7RxxsnfCyc4JZ3tnnOydcLazPOp1+gL+0xCiaKgabry9vdHpdERHR9ssj46OznOfGnt7exo1asTp06ezXG8wGDAYpG9FVu622jzfOICq5YugdUNRLOPIJMZmCCwZQot1/s7y5JuAkv3xNFoIetwSaGo/A06l8CovkSWzYiYuNY4bKTeyDSwZg4vRbFS7ZCutRnsvNN151Ov0tgFEsTyazCbr87shpijZae3uhZ47j472jtbwc3d5pnBk74yjnaPNfk72TjjaOaLVyFWIovCpGm70ej1NmjQhLCyMbt26AWA2mwkLC2P48OF5OobJZOLw4cN06dKlECstfXafuc6O07HY6zSMaPeArTaKYrnvUlJs3gJLUizk+8tZA05ellseOHvfeyxf0xJoXMrwLSJKqbjUOI5dP0Zscmy24eVmyk3Slfz9v+Ri74KXoxdeDl54OXrh6eBp89zLwQtXvStGk5EUUwop6XcmUzaP2c3feUw1pZKcnmxdZlbMgCWYJaUnkZSelEvFeWenscNOm8V0//L7nmvQkGJKITEtkaQ0S01JaUmkmFIASDenE2+MJ95YcH0V74YeTwdPvB29rZ+/t6P3vWV3/jw8HDwkDBVTZsWc6e9AsinZOu9k70Qjn0aq1af6aalRo0bRv39/mjZtSvPmzZk9ezaJiYnWq6f69etHQEAA06ZNA2Dy5Mk88sgjVK9enVu3bjFjxgwuXLjAkCFD1HwbJYqiKHz6h+VS+l7NKhHo6ZT/gyTfhO9egMv78r+vwd02qFjny9vOO3lbWmO0uvy/hihREowJbL20lQ3nN7Dr6q48t1C46d0yBZSsHj0dPHGwU288LEVRSDenW7/8U9NT782bUjGajOi0OnQaHfZa++zDSRbLdBpdgQ+HkW5OJzk92RJ67gSepLQk6/PEtMR769OSSExPtG5zd711u7RkEtMTreEuOT2Z5PRkYpNjOXnzZI516DQ6PBw8bELQ3T/XjCHI29Ebd4O7BKE77gaPpPQka8DOGLSt8/c/vzN//3rr/veF+Zw09mnMN52/KaJ3nJnq4aZnz55cu3aNCRMmEBUVRcOGDdmwYYO1k/HFixfRZhhM7ebNmwwdOpSoqCg8PDxo0qQJu3btok6dOmq9hRLnz5PX+OfCTQx2Woa3q57/AygKrHvjXrCxcwBnn9wDi9Od5XIJtsDyI/fn5T/ZeG4jf13+y+bUUSXXSvg7++Pp6Jk5sNydd/DCvoSMT6TRaLDX2WOvs8dNX/w77ttp7XDVu+Kqdy2Q4ymKQqop1Rp6EowJ3Ei5QWxyrLU1LuP89eTr3Ey9iUkxEZscS2xybK6vYaexs7bGeTp64u3gbW0RyhhyDToDWo0WO60dWo0WnUaX7Xxhj6FmE0LSkq1h5G5IzPP8nQB6N5gkpycXat33u9u/7G4/NAc7Byq5VSrSGu6nURQlh04NpU98fDzu7u7ExcXh5lb8v2QKmqIoPDN3J4evxDH08SqMe+oBQuH+pfDLm5ZOvIM2QkATue+SyBOjyciOKzvYcG4D2y5vs/kSDnILolOVTnQK6kS1ctVUrFIUB2nmNG6m3MwUfO4PQbEpscSlxhVKDTqNLs9BKOO8TqOztsTptJZjpKan2oSQu8GkMGnQWMOGo52jtUP83U7y9z/PGE7uf2591Dlm6nBfVC1m+fn9Vr3lRhStP45Fc/hKHE56Ha+2foAfkGsRllsYALSfCBWbFmyBotRJM6fx99W/2XB+A1subiEhLcG6LsAlgE5BnehUpRM1PUr5Pc1Evthr7fFx8sHHKfd+dWmmNEtLUEpspqviMoahGyk3bK4sMytmTIop2+PevTItzZxWkG8tk7sh5G7H7KzmHe0cLc/tHa2duO8uy27eoDOU2b9TEm7KEJNZsV4hNejRKni55PP0UFoK/DgI0pMtI/y2zFunb1H2mMwm/on+h9/P/U7YxTBupd6yrvNx8iE0KJTOQZ2p512vzH75ioJjr7PH19kXX2ff3De+j6Io1pCTMfBknDcpJsuVa0o6ZrPtskzrFXOm5SbFZG39yCqMOOgc5O9BAZNwU4b8eugqEdG3cXOwY+gTVfN/gM0TIfqIpe9MtwVyY0lhw6yYCY8JZ8P5Dfxx/g+up1y3rvN08OTJyk/SqUonGvk0ko6fotjQaDSW00foZFyfUkTCTRmRbjIze/MpAF55oirujvnsiBnxO+xZYJnvvgBc8/8vJFH6KIrC0etH+f3c72w8v5HopHtjVrkb3OlQqQOdqnSiqW9T7LTydSOEKBrybVNGrD5whXOxiXg66xnwaJX87RwfCWtft8w/MgyCOxZ8gaLEUBSFkzdPsuH8Bjac28DlhMvWdc72zrSv1J7QoFBa+rcsMVczCSFKFwk3ZUBquonPwyytNq+1roaLIR9/7GYTrHnFchsEvwbQYWIhVSmKu7NxZ9lwbgMbzm/gXNw563JHO0daV2xNpyqdeCzgMQw6udRfCKEuCTdlwMp9l7hyKxkfVwN9W1bO3847P4dzf4G9E/RYLGPUlDGXbl9i4/mN/H7ud5sB1/RaPY9XfJxOQZ14ouITONk/wECQQghRSCTclHIpaSa+2GK579aIdtVxsM/HaL+X/4GtUyzzXWaAdzG8uaZ4YGbFTGxyLFGJUfemJMtjdGI0UYlRxCTHWLe309jRskJLOlfpTNvAtrjo5W7rQojiScJNKfft7gvE3E4loJwjPZvlY8TIlHjLZd/mdKj7HDTsU3hFigKnKAq3Um8RmRiZfXBJisn1/kxajZbmfs3pFNSJDpU74G6Qu60LIYo/CTelWEJqOvP/PAPAmx2C0dvl8fJbRYH1o+DWBShXCZ7+TEYgLmZuG29nCi3W4HLneaopNdfjaDVayjuWx9/ZHz9nv3uTk+WxomtFCTRCiBJHwk0ptnTnOW4kGqni7cxzjQLyvuPB5XB4FWh08PwicCxXaDWKzBLTEq2tK9FJlrBy9/ndMJOYlpinY3k5eGUZWu5O3o7ecom2EKLUkW+1UiouKY0v/zoLwMgOwdjp8thqc/0M/DbaMt92LAQ2L6QKyx5FUUhIS7C2rkQnRhOddGfKEGYy3p4gJ+4G90xhxdfJ12ZeBiUTQpRFEm5KqYXbz3I7JZ2avq50bVAhbzulGy39bIwJEPQ4PDaqcIssRRRFId4Yfy+oZAwvGZ4npSfl6Xiueld8nSzDyfs52YaWu8FFrlASQoisSbgpha4npLJ4p2UcklFP1kCrzWN/mS2TITIcHD2g+5egzceVVWXAlYQrnLl15l7/lgytLtFJ0Xm+w6+7wd0SXDKGF2fb5xJchBDiwUm4KYUW/HmGJKOJ+gHuPFknj7dJOB0Gu76wzD87D9zz0UenlLqWdI29UXvZG7WXPZF7uJJwJdd9yhnKWVtWrGElw3MfJx8JLkIIUcgk3JQy0fEpLNt9AYC3n6yRtzvNJlyDNa9a5psNgVpPFWKFxVdcahz7ovaxJ3IPe6P2cjburM16O40d1T2q2/Rtyfjo4+SDg52DStULIYS4S8JNKTN3y2lS0800rexB6xrlc9/BbIa1r0JiDPjUgSc/Kvwii4mktCT2R++3tsycuHECBcW6XoOGWp61aOHfghb+LWjs01haXYQQogSQcFOKXLqRxPJ9FwEYHVozb602e+bD6c1g52C5vYK9YyFXqZ5UUyoHYw6yJ2oPeyP3ciT2SKZB7Kq5V6O5f3Na+LWgqV9TGeNFCCFKIAk3pcicsFOkmRQeq+7NI1W9ct/hajhsunMjzNCp4FO7UOsraunmdI5eP8reyL3sidpDeEx4poHtAlwCLC0zfi1o5teM8k55aO0SQghRrEm4KSXOXkvgpwOXAcsVUrlKTYCfBoM5DWo9DU0HFXKFhc+smDl586S1z8z+6P2ZBrsr71je2jLTzK8ZFV0rqlStEEKIwiLhppSYvfkUZgXa1/KhcSWP3HfYMAaunwa3AHjmixJ5ewVFUTgff97aMrMvah+3Um/ZbOOmd6O5X3NLoPFvQRW3Knk7XSeEEKLEknBTCpyIiueXQ1eBPLbaHP4R/v0/QAPPfQVOnvl+zTRzGl8e/JJj14+h1WjRaDRo0d6b12jRkmFeo0VDhvk72+e2/u7z+/c5F3eOvZF7be5aDeBk50QT3ya08G9Bc7/m1PSsiVaTx9GZhRBClAoSbkqBWX+cRFHgqfr+1K2QSwfYm+fh17cs80/8F4Iey/frmRUzE3ZO4Nezv+a/2AKm1+pp5NOI5v7Nae7XnLredbHX2qtdlhBCCBVJuCnhTsfc5o9j0Wg18FbH4Jw3NqXBT0MgNR4CW0DrMfl+PUVR+Hjvx/x69ld0Gh0jGo3Aw8EDs2LGrJhRFAUzGeYVMwrKvfUZ57PY1kyG+Ry293b0prlfc0LKh8jYMkIIIWxIuCnhVu23dCJuV8uX6j6uOW+87WO4vA8M7vDcQtDl/49/Xvg8fjjxAxo0fPTYRzxd9ekHKVsIIYQoNNIZoQRLN5lZc8ByS4AXmuZy1c+57bD9U8v8M5+DR+V8v96yo8v48tCXALzX4j0JNkIIIYolCTcl2PbTscTcTsXTWU/bmj7Zb5h0A1a/AijQqC/U7Z7v11pzag0z/pkBwIhGI+hVq9cDVi2EEEIULgk3JdiPd05JPduwAnq7bP4oFQV+Hg63r4JXMHSenu/X2XRhEx/s/gCA/nX6M7T+0ActWQghhCh0Em5KqLikNDYdjQagR5McTknt+xoi1oNOb7m9gt45X6+z6+ouxvw1BrNi5rng53i76dsyTowQQohiTcJNCbXu0FWMJjO1/d2yv/w7+ihsHGeZ7zgZ/Bvk6zXCY8IZuXUkaeY0OlbuyIRHJkiwEUIIUexJuCmh7p6SyrbVxpgEPw4GUyoEPwktXs3X8SNuRPB62OskpyfTqkIrPn78Y3Ra3cOWLYQQQhQ6CTcl0OmY2xy8dAs7rYZnG1bIeqM/xsG14+DiC8/+L1+3V7gYf5H/bPoPt423aVi+IZ+1+Qy9Tl9A1QshhBCFS8JNCfTjfsvl321q+uDtYsi8wfFf4J/FlvnuC8Al73e6jk6MZugfQ7mecp0aHjWY234uTvZOBVG2EEIIUSQk3JQwJrPCmn9zOCUVd9lydRTAo29CtXZ5PvbNlJu8sukVriZepZJrJb7s+CXuhlxu5yCEEEIUM8Ui3MybN4+goCAcHBxo0aIFe/fuzdN+y5cvR6PR0K1bt8ItsBjZfuoa0fGpeDjZ067WfWPbmE2W8WxSbkGFRtD2/TwfN8GYwGubX+Ns3Fl8nHxY+ORCvB29C7Z4IYQQogioHm5WrFjBqFGjmDhxIgcOHCAkJITQ0FBiYmJy3O/8+fOMHj2axx9/vIgqLR7ujW0TkHlsm+2fwoWdoHeB5xeBXd76yaSkp/DG1jc4ev0oHgYPFnZcSAWXbPryCCGEEMWc6uFm1qxZDB06lIEDB1KnTh0WLFiAk5MTixcvznYfk8lEnz59mDRpElWrVi3CatUVl5TGH8eyGdvm4t+We0cBPPUpeFXL0zHTzGn898//si9qH872zszvOJ+q5crOZyqEEKL0UTXcGI1G9u/fT4cOHazLtFotHTp0YPfu3dnuN3nyZHx8fBg8eHCur5Gamkp8fLzNVFL9cugqxnQztfxcqVvB7d6K5FuWu30rJmjQE0LydmsEs2Jmws4JbLu8DYPOwBftvqCuV93CKV4IIYQoIqqGm9jYWEwmE76+vjbLfX19iYqKynKfHTt2sGjRIhYuXJin15g2bRru7u7WKTAw8KHrVkvGsW2sg+mZzfDLmxB3CTyqQJeZeTqWoihM2zONX8/+ip3Gjk9bf0ozv2aFVboQQghRZFQ/LZUft2/fpm/fvixcuBBv77x1dh07dixxcXHW6dKlS4VcZeE4HXOb8Dtj23RrFGBZmG6Eta/CsbWgtYMei8DBLcfj3DU3fC7LI5ajQcNHj31E68DWhVe8EEIIUYTs1Hxxb29vdDod0dHRNsujo6Px8/PLtP2ZM2c4f/48Xbt2tS4zm80A2NnZERERQbVqtn1NDAYDBkMWY8GUMJnGtkm9DSv7wZktoNHBs/MgoEmejvXN0W/46tBXAIxrMY6nqj5VaHULIYQQRU3Vlhu9Xk+TJk0ICwuzLjObzYSFhdGyZctM29eqVYvDhw8THh5unZ555hnatm1LeHh4iT7llJNMY9skxMDSpyzBxt4ZXlqZ5342a06tYeY/llNXbzR6g561ehZa3UIIIYQaVG25ARg1ahT9+/enadOmNG/enNmzZ5OYmMjAgQMB6NevHwEBAUybNg0HBwfq1atns3+5cuUAMi0vTWzGtvG5DYt6wM3z4OQNfVbmucXmj/N/8MHuDwAYWHcgQ+oPKbyihRBCCJWoHm569uzJtWvXmDBhAlFRUTRs2JANGzZYOxlfvHgRrbZEdQ0qcHc7Er8eHId+aSgkXQePIHh5dZ4v+d51ZRdjto/BrJh5Pvh53mryltzhWwghRKmkURRFUbuIohQfH4+7uztxcXG4ueWt862a4pLTaDZlM63MB1js9AXa9GTwbwh9VoGLT677A4THhPPKpldITk8mNCiU6Y9Plzt8CyGEKFHy8/utesuNyNmvh67yjLKV6fqFaNPNUK09vLgMDC552j/iRgSvh71OcnoyjwY8yrTHpkmwEUIIUapJuCnOFAX+mslM+2WW5yG94ZkvQGefp90vxF/gP5v+w23jbRr5NOKzNp9hn8d9hRDqMJlMpKWlqV2GEKrQ6/UF0hVFwk1xZTZxa/Vb9Em0BJuk5m/g1Hky5LGfTFRiFK/88QrXU65Ty7MWc9vPxdHOsTArFkI8BEVRiIqK4tatW2qXIoRqtFotVapUQa/P270RsyPhpjhKS4afhlDuxK+YFQ0/eA+jT5cP87z7zZSb/GfTf7iaeJXKbpWZ32E+bvri379IiLLsbrDx8fHByclJOvyLMsdsNnP16lUiIyOpVKnSQ/0dkHBT3CTdgB96w6W/MWLHm2nDeLbta3nePcGYwKubX+Vs3Fl8nXxZ2HEh3o55G81ZCKEOk8lkDTZeXl5qlyOEasqXL8/Vq1dJT0/H3v7Bu1GU7Wusi5tbl2BxJ7j0N+n2rvRNHcvfDo/RrpZv7vsCKekpjNgygmPXj+Fh8OCrJ7/C38W/kIsWQjysu31snJycVK5ECHXdPR1lMpke6jgSboqL6KOw6EmIjQDXCnwS8Dl7lNo82zAAvV3uf0xp5jRG/zmaf6L/wcXehQUdF1DVvWoRFC6EKChyKkqUdQX1d0DCTXFwfgcs7gy3r0L5WsS//DtLT1v+BdejScVcdzcrZt7f8T5/Xv4Tg87AF+2+oI5XncKuWgghhCiWJNyo7ega+LY7pMZBpZYw8Hd+Oa/BmG6mpq8rdSvk3BFYURSm7pnKb+d+w05jx6w2s2jq17SIihdCiIIXFBTE7Nmz87z9tm3b0Gg0cqWZsJJwo6Y9X8KqgWAyQu2u0HctOHlab7fQo0nFHJvozIqZqXumsiJiBRo0TH18Kk9UfKKIihdClHUajSbH6YMPPnig4+7bt49XXnklz9u3atWKyMhI3N3dH+j1ROkjV0upQVFg8wewc7blebMh0PkT0Oo4cy2Bfy/eQqfV8GyjCtkewqyYmbx7Mj+d+gkNGj5o9QGdq3QukvKFEAIgMjLSOr9ixQomTJhARESEdZmLy72R1BVFwWQyYWeX+89O+fLl81WHXq/Hz88vX/uUFkaj8aHHhCmNpOWmqJnSYM2r94JNu/HQZSbcuSXCT3dabdrUKI+Pq0PWhzCbmLBzAj+d+gmtRstHj33Ec8HPFUX1QogioigKScZ0Vaa83nLQz8/POrm7u6PRaKzPT5w4gaurK7///jtNmjTBYDCwY8cOzpw5w7PPPouvry8uLi40a9aMzZs32xz3/tNSGo2Gr7/+mu7du+Pk5ERwcDDr1q2zrr//tNTSpUspV64cGzdupHbt2ri4uNCpUyebMJaens4bb7xBuXLl8PLyYsyYMfTv359u3bpl+36vX79O7969CQgIwMnJifr16/PDDz/YbGM2m/nkk0+oXr06BoOBSpUqMWXKFOv6y5cv07t3bzw9PXF2dqZp06bs2bMHgAEDBmR6/ZEjR9KmTRvr8zZt2jB8+HBGjhyJt7c3oaGhAMyaNYv69evj7OxMYGAgr7/+OgkJCTbH2rlzJ23atMHJyQkPDw9CQ0O5efMmy5Ytw8vLi9TUVJvtu3XrRt++fbP9PIozabkpSqm3YWU/OLMFNDrLrRQa9bGuNpkVVh+4AmTfkTjdnM64HeP47dxv6DQ6pj42lS5VuxRJ+UKIopOcZqLOhI2qvPaxyaE46Qvm5+Hdd99l5syZVK1aFQ8PDy5dukSXLl2YMmUKBoOBZcuW0bVrVyIiIqhUqVK2x5k0aRKffPIJM2bM4IsvvqBPnz5cuHABT0/PLLdPSkpi5syZfPvtt2i1Wl5++WVGjx7Nd999B8D06dP57rvvWLJkCbVr1+bzzz9n7dq1tG3bNtsaUlJSaNKkCWPGjMHNzY3169fTt29fqlWrRvPmzQEYO3YsCxcu5LPPPuOxxx4jMjKSEydOAJCQkEDr1q0JCAhg3bp1+Pn5ceDAAcxmc74+02+++YbXXnuNnTt3WpdptVrmzJlDlSpVOHv2LK+//jrvvPMO//vf/wAIDw+nffv2DBo0iM8//xw7Ozu2bt2KyWTihRde4I033mDdunW88MILAMTExLB+/Xr++OOPfNVWXEi4KSoJMfDdCxAZDvZOlptfBne02WTn6Vii4lMo52RPu9qZ7/idZk7j3b/e5Y8Lf2CnseOT1p/QsXLHTNsJIURxMXnyZDp2vPc95enpSUhIiPX5hx9+yJo1a1i3bh3Dhw/P9jgDBgygd+/eAEydOpU5c+awd+9eOnXqlOX2aWlpLFiwgGrVqgEwfPhwJk+ebF3/xRdfMHbsWLp37w7A3Llz+e2333J8LwEBAYwePdr6fMSIEWzcuJGVK1fSvHlzbt++zeeff87cuXPp378/ANWqVeOxxx4D4Pvvv+fatWvs27fPGsqqV6+e42tmJTg4mE8++cRm2ciRI63zQUFBfPTRR7z66qvWcPPJJ5/QtGlT63OAunXrWudfeukllixZYg03//d//0elSpVsWo1KEgk3ReH6Gfi/5+DmeXDyhj4rIaBJps3udiR+NqQCBjvbO3cbTUZG/zmarZe2Yq+159PWn9K2Uvb/whBClGyO9jqOTQ5V7bULStOmtldvJiQk8MEHH7B+/XoiIyNJT08nOTmZixcv5nicBg0aWOednZ1xc3MjJiYm2+2dnJyswQbA39/fun1cXBzR0dHW1hYAnU5HkyZNcmxFMZlMTJ06lZUrV3LlyhWMRiOpqanWwRePHz9Oamoq7du3z3L/8PBwGjVqlG1rU141aZL592Pz5s1MmzaNEydOEB8fT3p6OikpKSQlJeHk5ER4eLg1uGRl6NChNGvWjCtXrhAQEMDSpUsZMGBAiR17ScJNYbu8H75/AZKug0cQvLwavKpl2iwuOY2NR6MA6NEk0GZdqimVt7a+xfYr29Fr9cxuO5vHKz5eFNULIVSi0WgK7NSQmpydnW2ejx49mk2bNjFz5kyqV6+Oo6MjPXr0wGg05nic+4fi12g0OQaRrLbPa1+i7MyYMYPPP/+c2bNnW/u3jBw50lq7o2PONyfObb1Wq81UY1Z3iL//Mz1//jxPP/00r732GlOmTMHT05MdO3YwePBgjEYjTk5Oub52o0aNCAkJYdmyZTz55JMcPXqU9evX57hPcSYdigvTqU3wzdOWYOMfAoM3ZRlsANYfiiT1ztg29QLujW2TnJ7MiLARbL+yHQedA3Pbz5VgI4QosXbu3MmAAQPo3r079evXx8/Pj/PnzxdpDe7u7vj6+rJv3z7rMpPJxIEDB3Lcb+fOnTz77LO8/PLLhISEULVqVU6ePGldHxwcjKOjI2FhYVnu36BBA8LDw7lx40aW68uXL2/T6RksrT252b9/P2azmU8//ZRHHnmEGjVqcPXq1UyvnV1ddw0ZMoSlS5eyZMkSOnToQGBgYI7bF2cSbgrLv9/B9z0hLQmqtYMB68Elcz+au37cfwmwHdsmKS2J4WHD2R25G0c7R/7X4X+0rNCySMoXQojCEBwczOrVqwkPD+fgwYO89NJL+e5QWxBGjBjBtGnT+Pnnn4mIiODNN9/k5s2bOZ6GCQ4OZtOmTezatYvjx4/zn//8h+joaOt6BwcHxowZwzvvvMOyZcs4c+YMf//9N4sWLQKgd+/e+Pn50a1bN3bu3MnZs2f56aef2L17NwDt2rXjn3/+YdmyZZw6dYqJEydy5MiRXN9L9erVSUtL44svvuDs2bN8++23LFiwwGabsWPHsm/fPl5//XUOHTrEiRMnmD9/PrGxsdZtXnrpJS5fvszChQsZNGhQvj7P4kbCTUFTFPhrBvz8OigmaNALeq8Ag2u2u5y5lsCB+8a2SUxL5LXNr7E3ai/O9s582fFLmvk1K6p3IYQQhWLWrFl4eHjQqlUrunbtSmhoKI0bNy7yOsaMGUPv3r3p168fLVu2xMXFhdDQUBwcsh6CA+D999+ncePGhIaG0qZNG2tQyWj8+PG8/fbbTJgwgdq1a9OzZ09rXx+9Xs8ff/yBj48PXbp0oX79+nz88cfodJY+TqGhoYwfP5533nmHZs2acfv2bfr165frewkJCWHWrFlMnz6devXq8d133zFt2jSbbWrUqMEff/zBwYMHad68OS1btuTnn3+2GXfI3d2d559/HhcXlxwviS8JNMrDnoQsYeLj43F3dycuLg43t5xvbZBvZhP8/g7s+9ry/NGR0OEDyKVD1icbTvC/bWdoV8uHxQOaEW+M57XNr3Ho2iFc7V1Z0HEBDco3yPEYQoiSKyUlhXPnzlGlSpUcf1xF4TGbzdSuXZsXX3yRDz/8UO1yVNO+fXvq1q3LnDlzVHn9nP4u5Of3u+T3Visu0pJh9VA4/guggc7TocV/ct3t/rFt4lLjeGXTKxy7fgx3gztfdvySul51czmKEEKI/Lhw4QJ//PEHrVu3JjU1lblz53Lu3DleeukltUtTxc2bN9m2bRvbtm2zuVy8pJJwU1AOrbQEG50enlsIdbvlabe7Y9u4O9rTpIo9gzcOJuJmBB4GDxY+uZCanjULt24hhCiDtFotS5cuZfTo0SiKQr169di8eTO1a9dWuzRVNGrUiJs3bzJ9+nRq1iz5vzsSbgpK435w7QTUegqCHsvzbnfHtglt4MSrYUM5fes0Xg5efP3k11T3yP/gTkIIIXIXGBhoM8JvWVfUV6wVNgk3BUWjgU7Tct8ug/gUy9g2Grt4DqbP52rSBXwcffg69GuquFcppEKFEEKI0k3CjYrWH4rEyA3cqy7iatI1/Jz9WPTkIiq5ZX9/FSGEEELkTMKNin44EI5T5a8w6W4Q4BLAotBFBLgEqF2WEEIIUaJJuFHJzvMnOGM3A639LSo4V2RppyX4OfupXZYQQghR4km4UcG5uHO8tf0VtPa3cFD8+LbLN/g4ZT96sRBCCCHyTkYoLmJnbp1h4IaBJJtvYkrx5e36n0uwEUIIIQqQhJsiFHEjgkEbB3E95TqmFH/sYl6nW4OSP56AEEI8jDZt2jBy5Ejr86CgIGbPnp3jPhqNhrVr1z70axfUcUTxIuGmiBy7fozBfwzmRsoNXDVBJF0YyrP1a+Bgr1O7NCGEeCBdu3alU6dOWa7bvn07Go2GQ4cO5fu4+/bt45VXXnnY8mx88MEHNGzYMNPyyMhIOnfuXKCvJe45evQozz//PEFBQWg0mlxDa0GRcFMEDl87zJA/hhCXGkcdz3pcPz0QzE70aFJR7dKEEOKBDR48mE2bNnH58uVM65YsWULTpk1p0CD/98UrX748Tk5OBVFirvz8/DAYDEXyWsWJ0WgsktdJSkqiatWqfPzxx/j5Fd1FMxJuCtm/Mf8ydNNQbhtv09inMZ29J5JqNBDs40KDiu5qlyeEKK4UBYyJ6kx5vJ/y008/Tfny5Vm6dKnN8oSEBFatWsXgwYO5fv06vXv3JiAgACcnJ+rXr88PP/yQ43HvPy116tQpnnjiCRwcHKhTpw6bNm3KtM+YMWOoUaMGTk5OVK1alfHjx5OWlgbA0qVLmTRpEgcPHkSj0aDRaKw1339a6vDhw7Rr1w5HR0e8vLx45ZVXSEhIsK4fMGAA3bp1Y+bMmfj7++Pl5cWwYcOsr5WVM2fO8Oyzz+Lr64uLiwvNmjVj8+bNNtukpqYyZswYAgMDMRgMVK9enUWLFlnXHz16lKeffho3NzdcXV15/PHHOXPmDJD5tB5At27dGDBggM1n+uGHH9KvXz/c3NysLWM5fW53/fLLLzRr1gwHBwe8vb3p3r07AJMnT6ZevXqZ3m/Dhg0ZP348AM2aNWPGjBn06tWrSEOkXC1ViPZF7WNY2DCS05Np5teMue3m0vfrcMByk0xNLncLF0KUYWlJMLWCOq/93lXQO+e6mZ2dHf369WPp0qWMGzfO+p22atUqTCYTvXv3JiEhgSZNmjBmzBjc3NxYv349ffv2pVq1ajRv3jzX1zCbzTz33HP4+vqyZ88e4uLiMv2QA7i6urJ06VIqVKjA4cOHGTp0KK6urrzzzjv07NmTI0eOsGHDBmuocHfP/I/LxMREQkNDadmyJfv27SMmJoYhQ4YwfPhwmwC3detW/P392bp1K6dPn6Znz540bNiQoUOHZvkeEhIS6NKlC1OmTMFgMLBs2TK6du1KREQElSpZBm3t168fu3fvZs6cOYSEhHDu3DliY2MBuHLlCk888QRt2rRhy5YtuLm5sXPnTtLT03P9/DKaOXMmEyZMYOLEiXn63ADWr19P9+7dGTduHMuWLcNoNPLbb78BMGjQICZNmsS+ffto1qwZAP/++y+HDh1i9erV+aqtoBWLcDNv3jxmzJhBVFQUISEhfPHFF9n+T7969WqmTp3K6dOnSUtLIzg4mLfffpu+ffsWcdU5+zvyb0aEjSDFlEJL/5Z83u5zIm+a2H/hJloNdG8kg/UJIUq+QYMGMWPGDP7880/atGkDWE5JPf/887i7u+Pu7s7o0aOt248YMYKNGzeycuXKPIWbzZs3c+LECTZu3EiFCpawN3Xq1Ez9ZN5//33rfFBQEKNHj2b58uW88847ODo64uLigp2dXY6nRr7//ntSUlJYtmwZzs6WcDd37ly6du3K9OnT8fX1BcDDw4O5c+ei0+moVasWTz31FGFhYdmGm5CQEEJCQqzPP/zwQ9asWcO6desYPnw4J0+eZOXKlWzatIkOHToAULVqVev28+bNw93dneXLl2Nvbw9AjRo1cv3s7teuXTvefvttm2U5fW4AU6ZMoVevXkyaNMnm/QBUrFiR0NBQlixZYg03S5YsoXXr1jb1q0H1cLNixQpGjRrFggULaNGiBbNnzyY0NJSIiAh8fDJfIu3p6cm4ceOoVasWer2eX3/9lYEDB+Lj40NoaKgK7yCzHVd2MHLrSFJNqTwe8Diftf0Mg87ATwdOANC6Rnl83BxUrlIIUazZO1laUNR67TyqVasWrVq1YvHixbRp04bTp0+zfft2Jk+eDIDJZGLq1KmsXLmSK1euYDQaSU1NzXOfmuPHjxMYGGgNNgAtW7bMtN2KFSuYM2cOZ86cISEhgfT0dNzc3PL8Pu6+VkhIiDXYADz66KOYzWYiIiKs4aZu3brodPcuBvH39+fw4cPZHjchIYEPPviA9evXExkZSXp6OsnJyVy8eBGA8PBwdDodrVu3znL/8PBwHn/8cWuweVBNmzbNtCy3zy08PDzb0AYwdOhQBg0axKxZs9BqtXz//fd89tlnD1VnQVC9z82sWbMYOnQoAwcOpE6dOixYsAAnJycWL16c5fZt2rShe/fu1K5dm2rVqvHmm2/SoEEDduzYUcSVZ23bpW28seUNUk2ptA1sy+y2szHoDJjMCqsPXAGgR5NAdYsUQhR/Go3l1JAaUz5PmQ8ePJiffvqJ27dvs2TJEqpVq2b9oZ4xYwaff/45Y8aMYevWrYSHhxMaGlqgHVp3795Nnz596NKlC7/++iv//vsv48aNK7ROs/eHDI1Gg9lsznb70aNHs2bNGqZOncr27dsJDw+nfv361vocHR1zfL3c1mu1WpT7+kll1QcoY2iDvH1uub12165dMRgMrFmzhl9++YW0tDR69OiR4z5FQdVwYzQa2b9/v7UZDix/SB06dGD37t257q8oCmFhYURERPDEE09kuU1qairx8fE2U2HZdGETb219izRzGh0rd+TTNp+i1+kB2H3mOpFxKbg72tO+tgzaJ4QoPV588UXrv9qXLVvGoEGDrP1vdu7cybPPPsvLL79MSEgIVatW5eTJk3k+du3atbl06RKRkZHWZX///bfNNrt27aJy5cqMGzeOpk2bEhwczIULF2y20ev1mEymXF/r4MGDJCYmWpft3LkTrVZLzZoPPibZzp07GTBgAN27d6d+/fr4+flx/vx56/r69etjNpv5888/s9y/QYMGbN++PdtOy+XLl7f5fEwmE0eOHMm1rrx8bg0aNCAsLCzbY9jZ2dG/f3+WLFnCkiVL6NWrV66BqCioGm5iY2MxmUzWpr67fH19iYqKyna/uLg4XFxc0Ov1PPXUU3zxxRd07Ngxy22nTZtmPe/r7u5OYGDhtJpsubiF//75X9KVdDpX6cwnT3yCvfZeuv9x/yUAuob4y9g2QohSxcXFhZ49ezJ27FgiIyNtrtIJDg5m06ZN7Nq1i+PHj/Of//yH6OjoPB+7Q4cO1KhRg/79+3Pw4EG2b9/OuHHjbLYJDg7m4sWLLF++nDNnzjBnzhzWrFljs01QUBDnzp0jPDyc2NhYUlNTM71Wnz59cHBwoH///hw5coStW7cyYsQI+vbtm+l3Kj+Cg4NZvXo14eHhHDx4kJdeesmmpScoKIj+/fszaNAg1q5dy7lz59i2bRsrV64EYPjw4cTHx9OrVy/++ecfTp06xbfffktERARg6Uuzfv161q9fz4kTJ3jttde4detWnurK7XObOHEiP/zwAxMnTuT48eMcPnyY6dOn22wzZMgQtmzZwoYNGxg0aJDNOqPRSHh4OOHh4RiNRq5cuUJ4eDinT59+kI8yz1Q/LfUgXF1dCQ8PZ9++fUyZMoVRo0axbdu2LLcdO3YscXFx1unSpUuFUlNtz9r4OfvxTLVnmPbYNOy097ozxaekseGoJazJKSkhRGk0ePBgbt68SWhoqE3/mPfff5/GjRsTGhpKmzZt8PPzo1u3bnk+rlarZc2aNSQnJ9O8eXOGDBnClClTbLZ55plneOuttxg+fDgNGzZk165d1kuR73r++efp1KkTbdu2pXz58lleju7k5MTGjRu5ceMGzZo1o0ePHrRv3565c+fm78O4z6xZs/Dw8KBVq1Z07dqV0NBQGjdubLPN/Pnz6dGjB6+//jq1atVi6NCh1hYkLy8vtmzZQkJCAq1bt6ZJkyYsXLjQenps0KBB9O/fn379+lk787Zt2zbXuvLyubVp04ZVq1axbt06GjZsSLt27di7d6/NNsHBwbRq1YpatWrRokULm3VXr16lUaNGNGrUiMjISGbOnEmjRo0YMmRIvj/H/NAo95+oK0JGoxEnJyd+/PFHm//Z+/fvz61bt/j555/zdJwhQ4Zw6dIlNm7cmOu28fHxuLu7ExcXl+/OZrmJTY7F08ETrcY2My7fe5F3Vx+muo8Lm956Qi4BF0LYSElJ4dy5c1SpUgUHB7nYQJQsiqIQHBzM66+/zqhRox7qWDn9XcjP77eqLTd6vZ4mTZrYnM8zm82EhYVl2Rs+O2azOcsmxqLm7eidKdgA/LjfMnqnjG0jhBCiNLl27Rpz584lKiqKgQMHql2OleqXgo8aNYr+/fvTtGlTmjdvzuzZs0lMTLR+SP369SMgIIBp06YBlj40TZs2pVq1aqSmpvLbb7/x7bffMn/+fDXfRrbOxSbyj4xtI4QQohTy8fHB29ubr776Cg8PD7XLsVI93PTs2ZNr164xYcIEoqKiaNiwIRs2bLB23rp48SJa7b3WkMTERF5//XUuX76Mo6MjtWrV4v/+7//o2bOnWm8hRz/dabV5okZ5fGVsGyGEEKWIij1bcqRqnxs1FGafm/uZzAqPTd9CZFwKc19qxNMNVBpKXQhRrEmfGyEsSkWfm9Lu7tg2bg52dKj94JcRCiGEECLvJNwUortj2zzTsIKMbSOEEEIUEQk3heS2jG0jhBBCqELCTSH57XAkKWlmqpV3JqSiu9rlCCGEEGWGhJtCcm9sm0AZ20YIIYQoQhJuCsH52ET2nZexbYQQIi/atGnDyJEjrc+DgoKYPXt2jvtoNBrWrl370K9dUMcRxYuEm0Lw0wFLq83jweXxc5fLOoUQpVPXrl3p1KlTluu2b9+ORqPh0KFD+T7uvn37eOWVVx62PBsffPABDRs2zLQ8MjKSzp07F+hriXsWLlzI448/joeHBx4eHnTo0CHTvakKg4SbAmY2K9aB+3o0qahyNUIIUXgGDx7Mpk2buHz5cqZ1S5YsoWnTpjRo0CDfxy1fvjxOTk4FUWKu/Pz8MBgMRfJaxYnRaCyS19m2bRu9e/dm69at7N69m8DAQJ588kmuXLlSqK8r4aaA7T57natxKbg62NGxjoxtI4R4MIqikJSWpMqU17Fdn376acqXL8/SpUttlickJLBq1SoGDx7M9evX6d27NwEBATg5OVG/fv0s78id0f2npU6dOsUTTzyBg4MDderUYdOmTZn2GTNmDDVq1MDJyYmqVasyfvx40tLSAFi6dCmTJk3i4MGDaDQaNBqNteb7T0sdPnyYdu3a4ejoiJeXF6+88goJCQnW9QMGDKBbt27MnDkTf39/vLy8GDZsmPW1snLmzBmeffZZfH19cXFxoVmzZmzevNlmm9TUVMaMGUNgYCAGg4Hq1auzaNEi6/qjR4/y9NNP4+bmhqurK48//jhnzpwBMp/WA+jWrRsDBgyw+Uw//PBD+vXrh5ubm7VlLKfP7a5ffvmFZs2a4eDggLe3N927dwdg8uTJ1KtXL9P7bdiwofXu4t999x2vv/46DRs2pFatWnz99dfWe0gWJtVvv1Da3O1I/EyIjG0jhHhwyenJtPi+hSqvveelPTjZ595yYmdnR79+/Vi6dCnjxo2zXjyxatUqTCYTvXv3JiEhgSZNmjBmzBjc3NxYv349ffv2pVq1ajRv3jzX1zCbzTz33HP4+vqyZ88e4uLiMv2QA7i6urJ06VIqVKjA4cOHGTp0KK6urrzzzjv07NmTI0eOsGHDBmuocHfPfBVrYmIioaGhtGzZkn379hETE8OQIUMYPny4TYDbunUr/v7+bN26ldOnT9OzZ08aNmzI0KFDs3wPCQkJdOnShSlTpmAwGFi2bBldu3YlIiKCSpUqAZb7KO7evZs5c+YQEhLCuXPniI2NBeDKlSs88cQTtGnThi1btuDm5sbOnTtJT0/P9fPLaObMmUyYMIGJEyfm6XMDWL9+Pd27d2fcuHEsW7YMo9HIb7/9BsCgQYOYNGkS+/bto1mzZgD8+++/HDp0iNWrV2dZQ1JSEmlpaXh6euar9vyScFOAbqek8fuRSEBOSQkhyoZBgwYxY8YM/vzzT9q0aQNYTkk9//zzuLu74+7uzujRo63bjxgxgo0bN7Jy5co8hZvNmzdz4sQJNm7cSIUKllvYTJ06NVM/mffff986HxQUxOjRo1m+fDnvvPMOjo6OuLi4YGdnh5+fX7av9f3335OSksKyZctwdnYGYO7cuXTt2pXp06db73no4eHB3Llz0el01KpVi6eeeoqwsLBsw01ISAghISHW5x9++CFr1qxh3bp1DB8+nJMnT7Jy5Uo2bdpEhw4dAKhatap1+3nz5uHu7s7y5cuxt7cHoEaNGrl+dvdr164db7/9ts2ynD43gClTptCrVy8mTZpk834AKlasSGhoKEuWLLGGmyVLltC6dWub+jMaM2YMFSpUsL7PwiLhpgBlHNumYWA5tcsRQpRgjnaO7Hlpj2qvnVe1atWiVatWLF68mDZt2nD69Gm2b9/O5MmTATCZTEydOpWVK1dy5coVjEYjqampee5Tc/z4cQIDA63BBqBly5aZtluxYgVz5szhzJkzJCQkkJ6enu/7Bx4/fpyQkBBrsAF49NFHMZvNREREWMNN3bp10enutcz7+/tz+PDhbI+bkJDABx98wPr164mMjCQ9PZ3k5GQuXrwIQHh4ODqdjtatW2e5f3h4OI8//rg12Dyopk2bZlqW2+cWHh6ebWgDGDp0KIMGDWLWrFlotVq+//57Pvvssyy3/fjjj1m+fDnbtm0r9HuoSbgpQDK2jRCioGg0mjydGioOBg8ezIgRI5g3bx5LliyhWrVq1h/qGTNm8PnnnzN79mzq16+Ps7MzI0eOLNAOrbt376ZPnz5MmjSJ0NBQayvHp59+WmCvkdH9IUOj0WA2m7PdfvTo0WzatImZM2dSvXp1HB0d6dGjh/UzcHTMOUzmtl6r1WbqJ5VVH6CMoQ3y9rnl9tpdu3bFYDCwZs0a9Ho9aWlp9OjRI9N2M2fO5OOPP2bz5s0P1Mk8v6RDcQGRsW2EEGXViy++aP1X+7Jlyxg0aJD1H3g7d+7k2Wef5eWXXyYkJISqVaty8uTJPB+7du3aXLp0icjISOuyv//+22abXbt2UblyZcaNG0fTpk0JDg7mwoULNtvo9XpMJlOur3Xw4EESExOty3bu3IlWq6VmzZp5rvl+O3fuZMCAAXTv3p369evj5+fH+fPnrevr16+P2Wzmzz//zHL/Bg0asH379mw7LZcvX97m8zGZTBw5ciTXuvLyuTVo0CDHzr92dnb079+fJUuWsGTJEnr16pUpEH3yySd8+OGHbNiwIcvWo8Ig4aaAXLiRRHlXA4/J2DZCiDLGxcWFnj17MnbsWCIjI22u0gkODmbTpk3s2rWL48eP85///Ifo6Og8H7tDhw7UqFGD/v37c/DgQbZv3864ceNstgkODubixYssX76cM2fOMGfOHNasWWOzTVBQEOfOnSM8PJzY2FhSU1MzvVafPn1wcHCgf//+HDlyhK1btzJixAj69u1rPSX1IIKDg1m9ejXh4eEcPHiQl156yaalJygoiP79+zNo0CDWrl3LuXPn2LZtGytXrgRg+PDhxMfH06tXL/755x9OnTrFt99+S0REBGDpS7N+/XrWr1/PiRMneO2117h161ae6srtc5s4cSI//PADEydO5Pjx4xw+fJjp06fbbDNkyBC2bNnChg0bGDRokM266dOnM378eBYvXkxQUBBRUVFERUXZXIFWGCTcFJDWNcqz+912zHyh8JvbhBCiuBk8eDA3b94kNDTUpn/M+++/T+PGjQkNDaVNmzb4+fnRrVu3PB9Xq9WyZs0akpOTad68OUOGDGHKlCk22zzzzDO89dZbDB8+nIYNG7Jr1y7rpch3Pf/883Tq1Im2bdtSvnz5LC9Hd3JyYuPGjdy4cYNmzZrRo0cP2rdvz9y5c/P3Ydxn1qxZeHh40KpVK7p27UpoaCiNGze22Wb+/Pn06NGD119/nVq1ajF06FBrC5KXlxdbtmwhISGB1q1b06RJExYuXGg9PTZo0CD69+9Pv379rJ1527Ztm2tdefnc2rRpw6pVq1i3bh0NGzakXbt2mQbhCw4OplWrVtSqVYsWLWyv8Js/fz5Go5EePXrg7+9vnWbOnJnvzzE/NEpeBzQoJeLj43F3dycuLi7fnc2EEKIwpKSkcO7cOapUqVLoHS2FKGiKohAcHMzrr7/OqFGjHupYOf1dyM/vt3QoFkIIIcQDuXbtGsuXLycqKoqBAweqXY6VhBshhBBCPBAfHx+8vb356quv8PDwULscKwk3QgghhHggxbVni3QoFkIIIUSpIuFGCCGKieL6r2AhikpB/R2QcCOEECq7e0lvUlKSypUIoa67ozZnvL3Fg5A+N0IIoTKdTke5cuWIiYkBLOOtyC1cRFljNpu5du0aTk5O2Nk9XDyRcCOEEMXA3btV3w04QpRFWq2WSpUqPXS4l3AjhBDFgEajwd/fHx8fn2zvISREaafX69FqH77HjIQbIYQoRnQ63UP3NxCirJMOxUIIIYQoVSTcCCGEEKJUkXAjhBBCiFKlzPW5uTtAUHx8vMqVCCGEECKv7v5u52WgvzIXbm7fvg1AYGCgypUIIYQQIr9u376Nu7t7jttolDI23rfZbObq1au4uroW+CBZ8fHxBAYGcunSJdzc3Ar02MWRvN/STd5v6VbW3i+Uvfdc2t6voijcvn2bChUq5Hq5eJlrudFqtVSsWLFQX8PNza1U/I+UV/J+Szd5v6VbWXu/UPbec2l6v7m12NwlHYqFEEIIUapIuBFCCCFEqSLhpgAZDAYmTpyIwWBQu5QiIe+3dJP3W7qVtfcLZe89l7X3m1GZ61AshBBCiNJNWm6EEEIIUapIuBFCCCFEqSLhRgghhBClioQbIYQQQpQqEm4KyLx58wgKCsLBwYEWLVqwd+9etUsqNNOmTaNZs2a4urri4+NDt27diIiIULusIvHxxx+j0WgYOXKk2qUUqitXrvDyyy/j5eWFo6Mj9evX559//lG7rEJhMpkYP348VapUwdHRkWrVqvHhhx/m6f41JcFff/1F165dqVChAhqNhrVr19qsVxSFCRMm4O/vj6OjIx06dODUqVPqFFsAcnq/aWlpjBkzhvr16+Ps7EyFChXo168fV69eVa/gh5Tbn29Gr776KhqNhtmzZxdZfWqRcFMAVqxYwahRo5g4cSIHDhwgJCSE0NBQYmJi1C6tUPz5558MGzaMv//+m02bNpGWlsaTTz5JYmKi2qUVqn379vHll1/SoEEDtUspVDdv3uTRRx/F3t6e33//nWPHjvHpp5/i4eGhdmmFYvr06cyfP5+5c+dy/Phxpk+fzieffMIXX3yhdmkFIjExkZCQEObNm5fl+k8++YQ5c+awYMEC9uzZg7OzM6GhoaSkpBRxpQUjp/eblJTEgQMHGD9+PAcOHGD16tVERETwzDPPqFBpwcjtz/euNWvW8Pfff1OhQoUiqkxlinhozZs3V4YNG2Z9bjKZlAoVKijTpk1TsaqiExMTowDKn3/+qXYpheb27dtKcHCwsmnTJqV169bKm2++qXZJhWbMmDHKY489pnYZReapp55SBg0aZLPsueeeU/r06aNSRYUHUNasWWN9bjabFT8/P2XGjBnWZbdu3VIMBoPyww8/qFBhwbr//WZl7969CqBcuHChaIoqRNm938uXLysBAQHKkSNHlMqVKyufffZZkddW1KTl5iEZjUb2799Phw4drMu0Wi0dOnRg9+7dKlZWdOLi4gDw9PRUuZLCM2zYMJ566imbP+fSat26dTRt2pQXXngBHx8fGjVqxMKFC9Uuq9C0atWKsLAwTp48CcDBgwfZsWMHnTt3Vrmywnfu3DmioqJs/r92d3enRYsWZer7S6PRUK5cObVLKRRms5m+ffvy3//+l7p166pdTpEpczfOLGixsbGYTCZ8fX1tlvv6+nLixAmVqio6ZrOZkSNH8uijj1KvXj21yykUy5cv58CBA+zbt0/tUorE2bNnmT9/PqNGjeK9995j3759vPHGG+j1evr37692eQXu3XffJT4+nlq1aqHT6TCZTEyZMoU+ffqoXVqhi4qKAsjy++vuutIsJSWFMWPG0Lt371JzY8n7TZ8+HTs7O9544w21SylSEm7EQxk2bBhHjhxhx44dapdSKC5dusSbb77Jpk2bcHBwULucImE2m2natClTp04FoFGjRhw5coQFCxaUynCzcuVKvvvuO77//nvq1q1LeHg4I0eOpEKFCqXy/QqLtLQ0XnzxRRRFYf78+WqXUyj279/P559/zoEDB9BoNGqXU6TktNRD8vb2RqfTER0dbbM8OjoaPz8/laoqGsOHD+fXX39l69atVKxYUe1yCsX+/fuJiYmhcePG2NnZYWdnx59//smcOXOws7PDZDKpXWKB8/f3p06dOjbLateuzcWLF1WqqHD997//5d1336VXr17Ur1+fvn378tZbbzFt2jS1Syt0d7+jytr3191gc+HCBTZt2lRqW222b99OTEwMlSpVsn5/XbhwgbfffpugoCC1yytUEm4ekl6vp0mTJoSFhVmXmc1mwsLCaNmypYqVFR5FURg+fDhr1qxhy5YtVKlSRe2SCk379u05fPgw4eHh1qlp06b06dOH8PBwdDqd2iUWuEcffTTTpf0nT56kcuXKKlVUuJKSktBqbb8KdTodZrNZpYqKTpUqVfDz87P5/oqPj2fPnj2l9vvrbrA5deoUmzdvxsvLS+2SCk3fvn05dOiQzfdXhQoV+O9//8vGjRvVLq9QyWmpAjBq1Cj69+9P06ZNad68ObNnzyYxMZGBAweqXVqhGDZsGN9//z0///wzrq6u1nPz7u7uODo6qlxdwXJ1dc3Ul8jZ2RkvL69S28forbfeolWrVkydOpUXX3yRvXv38tVXX/HVV1+pXVqh6Nq1K1OmTKFSpUrUrVuXf//9l1mzZjFo0CC1SysQCQkJnD592vr83LlzhIeH4+npSaVKlRg5ciQfffQRwcHBVKlShfHjx1OhQgW6deumXtEPIaf36+/vT48ePThw4AC//vorJpPJ+v3l6emJXq9Xq+wHltuf7/3hzd7eHj8/P2rWrFnUpRYttS/XKi2++OILpVKlSoper1eaN2+u/P3332qXVGiALKclS5aoXVqRKO2XgiuKovzyyy9KvXr1FIPBoNSqVUv56quv1C6p0MTHxytvvvmmUqlSJcXBwUGpWrWqMm7cOCU1NVXt0grE1q1bs/z72r9/f0VRLJeDjx8/XvH19VUMBoPSvn17JSIiQt2iH0JO7/fcuXPZfn9t3bpV7dIfSG5/vvcrK5eCaxSllAzDKYQQQgiB9LkRQgghRCkj4UYIIYQQpYqEGyGEEEKUKhJuhBBCCFGqSLgRQgghRKki4UYIIYQQpYqEGyGEEEKUKhJuhBBCCFGqSLgRQpR5Go2GtWvXql2GEKKASLgRQqhqwIABaDSaTFOnTp3ULk0IUULJjTOFEKrr1KkTS5YssVlmMBhUqkYIUdJJy40QQnUGgwE/Pz+bycPDA7CcMpo/fz6dO3fG0dGRqlWr8uOPP9rsf/jwYdq1a4ejoyNeXl688sorJCQk2GyzePFi6tati8FgwN/fn+HDh9usj42NpXv37jg5OREcHMy6desK900LIQqNhBshRLE3fvx4nn/+eQ4ePEifPn3o1asXx48fByAxMZHQ0FA8PDzYt28fq1atYvPmzTbhZf78+QwbNoxXXnmFw4cPs27dOqpXr27zGpMmTeLFF1/k0KFDdOnShT59+nDjxo0ifZ9CiAKi9m3JhRBlW//+/RWdTqc4OzvbTFOmTFEURVEA5dVXX7XZp0WLFsprr72mKIqifPXVV4qHh4eSkJBgXb9+/XpFq9UqUVFRiqIoSoUKFZRx48ZlWwOgvP/++9bnCQkJCqD8/vvvBfY+hRBFR/rcCCFU17ZtW+bPn2+zzNPT0zrfsmVLm3UtW7YkPDwcgOPHjxMSEoKzs7N1/aOPPorZbCYiIgKNRsPVq1dp3759jjU0aNDAOu/s7IybmxsxMTEP+paEECqScCOEUJ2zs3Om00QFxdHRMU/b2dvb2zzXaDSYzebCKEkIUcikz40Qotj7+++/Mz2vXbs2ALVr1+bgwYMkJiZa1+/cuROtVkvNmjVxdXUlKCiIsLCwIq1ZCKEeabkRQqguNTWVqKgom2V2dnZ4e3sDsGrVKpo2bcpjjz3Gd999x969e1m0aBEAffr0YeLEifTv358PPviAa9euMWLECPr27Yuvry8AH3zwAa+++io+Pj507tyZ27dvs3PnTkaMGFG0b1QIUSQk3AghVLdhwwb8/f1tltWsWZMTJ04AliuZli9fzuuvv46/vz8//PADderUAcDJyYmNGzfy5ptv0qxZM5ycnHj++eeZNWuW9Vj9+/cnJSWFzz77jNGjR+Pt7U2PHj2K7g0KIYqURlEURe0ihBAiOxqNhjVr1tCtWze1SxFClBDS50YIIYQQpYqEGyGEEEKUKtLnRghRrMmZcyFEfknLjRBCCCFKFQk3QgghhChVJNwIIYQQolSRcCOEEEKIUkXCjRBCCCFKFQk3QgghhChVJNwIIYQQolSRcCOEEEKIUuX/AXGCo6WtRZlfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses1, label='Validation loss1')\n",
        "plt.plot(val_losses2, label='Validation loss2')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "OrDGkq60W3CQ",
        "outputId": "ad71c43b-8743-43cb-ad9c-f134ebdc0bbb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the network"
      ],
      "metadata": {
        "id": "onUPn2BWiifo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can modify your TestDataset, but you should be mindful to align it with the training dataset and its transformations."
      ],
      "metadata": {
        "id": "XyX--vszdIJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pt_path=\"/content/gdrive/MyDrive/mldl2/MLDL2_HW/simclr_resnet18_epoch10.pt\"\n",
        "base_encoder = eval(backbone)\n",
        "pre_model = SimCLR(base_encoder, projection_dim=projection_dim).cuda()\n",
        "pre_model.load_state_dict(torch.load(pt_path))\n",
        "pt_path=\"/content/gdrive/MyDrive/mldl2/MLDL2_HW/self_best_model.pth\"\n",
        "model = LinModel(pre_model.enc, feature_dim=pre_model.feature_dim, n_classes=10)\n",
        "model.load_state_dict(torch.load(pt_path))\n",
        "model.to(device)\n",
        "test_acc = run_epoch(model, val_loader, 90)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5XmE10IgwOt",
        "outputId": "4b1046f9-ac2a-42f1-89f3-73cd2d6571e7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test epoch 90, loss: 1.2671, acc: 0.5702: 100%|██████████| 1250/1250 [00:10<00:00, 122.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.2670931887626649, 0.5702)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_file, transform=None):\n",
        "        self.img =np.load(img_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.img[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image"
      ],
      "metadata": {
        "id": "ykaPM2xucE4T"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestDataset(img_file=\"./test_data.npy\",transform=val_transform2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "vQFoTVtDcmuk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_loader)).size()"
      ],
      "metadata": {
        "id": "nAd2Z9lxczmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba9bedb-0ae6-4df7-c3d1-bff4c817708c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Do not modify the cell below!!!!**\n"
      ],
      "metadata": {
        "id": "bziuPRznkj6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  ### List to store predictions\n",
        "  test_predictions = []\n",
        "\n",
        "  with torch.inference_mode():\n",
        "      for i, data in enumerate(tqdm(test_loader)):\n",
        "\n",
        "          data = data.float().to(device)\n",
        "          output = model(data)\n",
        "          ### Get most likely predicted  with argmax\n",
        "          predicted_labels = torch.argmax(output, dim=1)\n",
        "\n",
        "          test_predictions.extend(predicted_labels.cpu().tolist())\n",
        "\n",
        "  return test_predictions"
      ],
      "metadata": {
        "id": "oi9xht3BbHzi"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = test(model, test_loader)"
      ],
      "metadata": {
        "id": "iS8MQAgucE61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebba530-8ba9-4cb4-eea9-339602f47562"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [00:00<00:00, 197.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create CSV file with predictions\n",
        "saved_path=\"2019-17577_정지후_self_HW3.csv\"\n",
        "with open(saved_path, \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
      ],
      "metadata": {
        "id": "MyEZFN4-cC7F"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}